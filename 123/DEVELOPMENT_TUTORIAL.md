# å·¥ä½œæµå¯¹è¯æœºå™¨äºº - å®Œæ•´å¼€å‘æ•™ç¨‹

> ä»é›¶å¼€å§‹æ„å»ºæ™ºèƒ½å¯¹è¯å·¥ä½œæµç³»ç»Ÿ

---

## ğŸ“š ç›®å½•

1. [ç³»ç»Ÿæ¦‚è¿°](#1-ç³»ç»Ÿæ¦‚è¿°)
2. [åŸºç¡€æ¦‚å¿µ](#2-åŸºç¡€æ¦‚å¿µ)
3. [ç³»ç»Ÿæ¶æ„](#3-ç³»ç»Ÿæ¶æ„)
4. [å¼€å‘ç¯å¢ƒå‡†å¤‡](#4-å¼€å‘ç¯å¢ƒå‡†å¤‡)
5. [å¿«é€Ÿå¼€å§‹](#5-å¿«é€Ÿå¼€å§‹)
6. [æ ¸å¿ƒç»„ä»¶è¯¦è§£](#6-æ ¸å¿ƒç»„ä»¶è¯¦è§£)
7. [API å‚è€ƒ](#7-api-å‚è€ƒ)
8. [å®æˆ˜æ•™ç¨‹](#8-å®æˆ˜æ•™ç¨‹)
9. [é«˜çº§åŠŸèƒ½](#9-é«˜çº§åŠŸèƒ½)
10. [éƒ¨ç½²æŒ‡å—](#10-éƒ¨ç½²æŒ‡å—)
11. [æœ€ä½³å®è·µ](#11-æœ€ä½³å®è·µ)
12. [æ•…éšœæ’æŸ¥](#12-æ•…éšœæ’æŸ¥)

---

## 1. ç³»ç»Ÿæ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯å·¥ä½œæµå¯¹è¯æœºå™¨äººï¼Ÿ

å·¥ä½œæµå¯¹è¯æœºå™¨äººæ˜¯ä¸€ä¸ª**æ™ºèƒ½å¯¹è¯ç³»ç»Ÿ**ï¼Œå®ƒèƒ½å¤Ÿï¼š

- ğŸ—£ï¸ **ç†è§£è‡ªç„¶è¯­è¨€**ï¼šæ¥æ”¶ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥
- ğŸ”„ **æ‰§è¡Œå·¥ä½œæµ**ï¼šå°†ç”¨æˆ·éœ€æ±‚è½¬æ¢ä¸ºå¯æ‰§è¡Œçš„å·¥ä½œæµä»»åŠ¡
- â¸ï¸ **å¤„ç†ä¸­æ–­**ï¼šåœ¨éœ€è¦æ›´å¤šä¿¡æ¯æ—¶æš‚åœå¹¶è¯¢é—®ç”¨æˆ·
- ğŸ“Š **æ•°æ®åˆ†æ**ï¼šè°ƒç”¨å„ç§åˆ†æå·¥å…·å¤„ç†æ•°æ®
- ğŸ“ˆ **ç»“æœå±•ç¤º**ï¼šä»¥å¯è§†åŒ–çš„æ–¹å¼å±•ç¤ºç»“æœ

### 1.2 åº”ç”¨åœºæ™¯

```
ç”¨æˆ·ï¼š"å¸®æˆ‘å¯¹æ¯”åˆ†æä¸€ä¸‹é”€å”®æ•°æ®Q1å’ŒQ4çš„å·®å¼‚"
  â†“
æœºå™¨äººï¼šå¯åŠ¨å·¥ä½œæµ â†’ è¯†åˆ«éœ€è¦å¯¹æ¯”åˆ†æ
  â†“
æœºå™¨äººï¼š"è¯·é—®æ‚¨å¸Œæœ›ä½¿ç”¨å“ªç§å¯¹æ¯”æ–¹æ³•ï¼Ÿ"
  â†“
ç”¨æˆ·ï¼š"ä½¿ç”¨tæ£€éªŒï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"
  â†“
æœºå™¨äººï¼šæ¢å¤å·¥ä½œæµ â†’ æ‰§è¡Œtæ£€éªŒ â†’ ç”Ÿæˆå›¾è¡¨ â†’ è¿”å›ç»“æœ
```

### 1.3 æŠ€æœ¯æ ˆ

| æŠ€æœ¯ | ç”¨é€” | è¯´æ˜ |
|-----|------|-----|
| **Gradio** | Webç•Œé¢ | å¿«é€Ÿæ„å»ºæœºå™¨å­¦ä¹ åº”ç”¨çš„UIæ¡†æ¶ |
| **Python** | å¼€å‘è¯­è¨€ | æ ¸å¿ƒé€»è¾‘å®ç° |
| **PIL/Pillow** | å›¾åƒå¤„ç† | å¤„ç†å’Œå±•ç¤ºå¯è§†åŒ–ç»“æœ |
| **å¼‚æ­¥ç¼–ç¨‹** | å·¥ä½œæµç®¡ç† | å¤„ç†é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ |

---

## 2. åŸºç¡€æ¦‚å¿µ

### 2.1 å·¥ä½œæµï¼ˆWorkflowï¼‰

#### ä»€ä¹ˆæ˜¯å·¥ä½œæµï¼Ÿ

**å·¥ä½œæµ**æ˜¯ä¸€ç³»åˆ—æœ‰åºçš„ä»»åŠ¡æ­¥éª¤ï¼Œç”¨äºå®Œæˆå¤æ‚çš„ä¸šåŠ¡é€»è¾‘ã€‚

```
å·¥ä½œæµç¤ºä¾‹ï¼šæ•°æ®åˆ†ææµç¨‹

æ­¥éª¤1: æ•°æ®æ”¶é›†
   â†“
æ­¥éª¤2: æ•°æ®æ¸…æ´—
   â†“
æ­¥éª¤3: ç»Ÿè®¡åˆ†æ
   â†“
æ­¥éª¤4: ç»“æœå¯è§†åŒ–
   â†“
æ­¥éª¤5: ç”ŸæˆæŠ¥å‘Š
```

#### å·¥ä½œæµçŠ¶æ€

ä¸€ä¸ªå·¥ä½œæµåœ¨å…¶ç”Ÿå‘½å‘¨æœŸä¸­æœ‰å¤šç§çŠ¶æ€ï¼š

```python
# çŠ¶æ€è½¬æ¢å›¾
[æœªå¯åŠ¨] â†’ [è¿è¡Œä¸­] â†’ [ä¸­æ–­] â†’ [æ¢å¤] â†’ [å®Œæˆ]
                      â†“
                   [å¤±è´¥]
```

**å¸¸è§çŠ¶æ€ï¼š**

| çŠ¶æ€ | è¯´æ˜ | ç¤ºä¾‹ |
|-----|------|-----|
| `initialized` | å·²åˆå§‹åŒ– | å·¥ä½œæµåˆšåˆ›å»º |
| `running` | è¿è¡Œä¸­ | æ­£åœ¨æ‰§è¡Œä»»åŠ¡ |
| `interrupted` | ä¸­æ–­ç­‰å¾… | éœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯ |
| `completed` | å·²å®Œæˆ | æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæ¯• |
| `failed` | å¤±è´¥ | å‡ºç°é”™è¯¯ |

### 2.2 RunIDï¼ˆè¿è¡Œæ ‡è¯†ç¬¦ï¼‰

#### å®šä¹‰

**RunID** æ˜¯å·¥ä½œæµçš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œç”¨äºè·Ÿè¸ªå’Œç®¡ç†ç‰¹å®šçš„å·¥ä½œæµå®ä¾‹ã€‚

```python
# RunID ç¤ºä¾‹
run_20240126_143052_abc123
â”‚   â”‚        â”‚      â”‚
â”‚   â”‚        â”‚      â””â”€ å”¯ä¸€æ ‡è¯†ç¬¦
â”‚   â”‚        â””â”€ æ—¶é—´æˆ³
â”‚   â””â”€ æ—¥æœŸ
â””â”€ å‰ç¼€
```

#### ç”¨é€”

```python
# 1. å¯åŠ¨å·¥ä½œæµï¼Œè·å– RunID
run_id = start_workflow("åˆ†æé”€å”®æ•°æ®")
# è¾“å‡º: run_20240126_143052

# 2. ä½¿ç”¨ RunID æŸ¥è¯¢çŠ¶æ€
info = get_workflow_info(run_id)
# è¾“å‡º: {"status": "running", "progress": 50}

# 3. ä½¿ç”¨ RunID æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ
resume_workflow("ä½¿ç”¨tæ£€éªŒ", run_id)
```

### 2.3 çŠ¶æ€æœºï¼ˆState Machineï¼‰

#### æ¦‚å¿µ

**çŠ¶æ€æœº**æ˜¯ä¸€ç§æ•°å­¦æ¨¡å‹ï¼Œç”¨äºæè¿°ç³»ç»Ÿåœ¨ä¸åŒçŠ¶æ€ä¹‹é—´çš„è½¬æ¢ã€‚

```python
# ç®€åŒ–çš„çŠ¶æ€æœºå®ç°

class WorkflowStateMachine:
    def __init__(self):
        self.state = "initialized"
        self.transitions = {
            "initialized": ["running"],
            "running": ["completed", "interrupted", "failed"],
            "interrupted": ["running", "failed"],
            "failed": ["initialized"],
            "completed": []
        }

    def transition(self, new_state):
        if new_state in self.transitions[self.state]:
            self.state = new_state
            return True
        return False
```

#### åœ¨æˆ‘ä»¬ç³»ç»Ÿä¸­çš„åº”ç”¨

```python
# å·¥ä½œæµçŠ¶æ€è½¬æ¢
workflow_state = {
    "current_state": "interrupted",
    "history": ["initialized", "running", "interrupted"],
    "can_resume": True,
    "requires_input": True
}
```

### 2.4 å¯¹è¯å†å²ï¼ˆConversation Historyï¼‰

#### å®šä¹‰

**å¯¹è¯å†å²**æ˜¯ç”¨æˆ·ä¸ç³»ç»Ÿä¹‹é—´æ‰€æœ‰äº¤äº’çš„è®°å½•ï¼Œç”¨äºï¼š

- ğŸ§  **ä¸Šä¸‹æ–‡ç†è§£**ï¼šç†è§£å½“å‰å¯¹è¯çš„èƒŒæ™¯
- ğŸ”„ **çŠ¶æ€æ¢å¤**ï¼šä»ä¸­æ–­ç‚¹æ¢å¤å¯¹è¯
- ğŸ“Š **æ•°æ®åˆ†æ**ï¼šåˆ†æç”¨æˆ·éœ€æ±‚æ¨¡å¼

#### æ•°æ®ç»“æ„

```python
conversation_history = [
    {
        "role": "user",           # è§’è‰²ï¼šuser æˆ– assistant
        "content": "åˆ†æé”€å”®æ•°æ®", # æ¶ˆæ¯å†…å®¹
        "timestamp": "2024-01-26T14:30:52",  # æ—¶é—´æˆ³
        "metadata": {             # å…ƒæ•°æ®
            "run_id": "run_123",
            "intent": "analysis"
        }
    },
    {
        "role": "assistant",
        "content": "å¥½çš„ï¼Œè¯·é—®éœ€è¦åˆ†æå“ªäº›æŒ‡æ ‡ï¼Ÿ",
        "timestamp": "2024-01-26T14:30:53",
        "metadata": {
            "run_id": "run_123",
            "state": "interrupted"
        }
    }
]
```

### 2.5 å·¥å…·å‡½æ•°ï¼ˆTool Functionsï¼‰

#### å®šä¹‰

**å·¥å…·å‡½æ•°**æ˜¯æ‰§è¡Œç‰¹å®šä»»åŠ¡çš„ç‹¬ç«‹å‡½æ•°æ¨¡å—ï¼Œå¯ä»¥è¢«å·¥ä½œæµè°ƒç”¨ã€‚

```python
# å·¥å…·å‡½æ•°çš„æ ‡å‡†ç»“æ„

def tool_function(parameters: dict) -> dict:
    """
    å·¥å…·å‡½æ•°æ¨¡æ¿

    Args:
        parameters: ä»å·¥ä½œæµä¼ é€’çš„å‚æ•°å­—å…¸

    Returns:
        {
            "message": "æ‰§è¡Œç»“æœæ¶ˆæ¯",
            "result": {
                "files": ["æ–‡ä»¶è·¯å¾„åˆ—è¡¨"],
                "images": [PIL.Imageå¯¹è±¡åˆ—è¡¨]
            }
        }
    """
    # 1. å‚æ•°éªŒè¯
    # 2. æ‰§è¡Œä»»åŠ¡
    # 3. ç”Ÿæˆæ–‡ä»¶å’Œå›¾ç‰‡
    # 4. è¿”å›ç»“æœ
    pass
```

#### ç¤ºä¾‹

```python
def statistical_analysis(parameters: dict) -> dict:
    """ç»Ÿè®¡åˆ†æå·¥å…·"""

    # æå–å‚æ•°
    data_path = parameters.get("data_path")
    method = parameters.get("method", "t-test")

    # æ‰§è¡Œåˆ†æ
    result = perform_statistical_test(data_path, method)

    # ç”Ÿæˆå¯è§†åŒ–
    chart = create_visualization(result)

    # è¿”å›ç»“æœ
    return {
        "message": f"ç»Ÿè®¡åˆ†æå®Œæˆï¼Œä½¿ç”¨æ–¹æ³•: {method}",
        "result": {
            "files": [result.csv_path],
            "images": [chart]
        }
    }
```

### 2.6 å¼‚æ­¥å¤„ç†ï¼ˆAsynchronous Processingï¼‰

#### æ¦‚å¿µ

**å¼‚æ­¥å¤„ç†**å…è®¸ç³»ç»Ÿåœ¨ç­‰å¾…é•¿æ—¶é—´ä»»åŠ¡å®Œæˆæ—¶ï¼Œä¸é˜»å¡å…¶ä»–æ“ä½œã€‚

```python
# åŒæ­¥ vs å¼‚æ­¥

# åŒæ­¥æ–¹å¼ï¼ˆé˜»å¡ï¼‰
def start_workflow_sync(user_input):
    result = workflow.run()  # ç­‰å¾…å®Œæˆ
    return result  # åªæœ‰å®Œæˆåæ‰è¿”å›

# å¼‚æ­¥æ–¹å¼ï¼ˆéé˜»å¡ï¼‰
async def start_workflow_async(user_input):
    run_id = workflow.start()  # ç«‹å³è¿”å›ID
    return run_id  # ç«‹å³è¿”å›ï¼Œä¸ç­‰å¾…å®Œæˆ

# åç»­å¯ä»¥æŸ¥è¯¢çŠ¶æ€
result = await workflow.check_status(run_id)
```

#### åœ¨æˆ‘ä»¬çš„åº”ç”¨ä¸­

```python
# å·¥ä½œæµä¸éœ€è¦ç«‹å³å®Œæˆ
def handle_user_input(user_input):
    # 1. ç«‹å³å¯åŠ¨å·¥ä½œæµï¼Œè·å– runID
    run_id = start_workflow(user_input)

    # 2. ç«‹å³è¿”å›å“åº”ç»™ç”¨æˆ·
    return f"å·¥ä½œæµå·²å¯åŠ¨ï¼ŒID: {run_id}"

# ç”¨æˆ·å¯ä»¥ç¨åæŸ¥çœ‹ç»“æœ
def check_results(run_id):
    return get_workflow_info(run_id)
```

### 2.7 å›è°ƒæœºåˆ¶ï¼ˆCallbackï¼‰

#### å®šä¹‰

**å›è°ƒ**æ˜¯ä¸€ç§å‡½æ•°ï¼Œä½œä¸ºå‚æ•°ä¼ é€’ç»™å¦ä¸€ä¸ªå‡½æ•°ï¼Œåœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è¢«è°ƒç”¨ã€‚

```python
# å›è°ƒç¤ºä¾‹

def process_data(data, callback):
    """å¤„ç†æ•°æ®ï¼Œå®Œæˆåè°ƒç”¨å›è°ƒ"""
    result = analyze(data)
    callback(result)  # è°ƒç”¨å›è°ƒå‡½æ•°

# å®šä¹‰å›è°ƒå‡½æ•°
def on_complete(result):
    print(f"å¤„ç†å®Œæˆ: {result}")

# ä½¿ç”¨å›è°ƒ
process_data(my_data, on_complete)
```

---

## 3. ç³»ç»Ÿæ¶æ„

### 3.1 æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ç”¨æˆ·ç•Œé¢å±‚                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚ èŠå¤©å¯¹è¯æ¡†  â”‚  â”‚ ç»“æœç”»å»Š   â”‚  â”‚ æ–‡ä»¶ä¸‹è½½   â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¸šåŠ¡é€»è¾‘å±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚         å¯¹è¯å¤„ç†å™¨ (ChatHandler)              â”‚      â”‚
â”‚  â”‚  - å¤„ç†ç”¨æˆ·è¾“å…¥                               â”‚      â”‚
â”‚  â”‚  - ç®¡ç†å¯¹è¯å†å²                               â”‚      â”‚
â”‚  â”‚  - åè°ƒå·¥ä½œæµå’Œå·¥å…·                           â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                           â”‚                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚       å·¥ä½œæµç®¡ç†å™¨ (WorkflowManager)           â”‚     â”‚
â”‚  â”‚  - å¯åŠ¨/æ¢å¤å·¥ä½œæµ                             â”‚     â”‚
â”‚  â”‚  - çŠ¶æ€è·Ÿè¸ª                                   â”‚     â”‚
â”‚  â”‚  - å‚æ•°è§£æ                                   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å·¥å…·æ‰§è¡Œå±‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ç»Ÿè®¡åˆ†æ  â”‚  â”‚è¶‹åŠ¿åˆ†æ  â”‚  â”‚ç›¸å…³æ€§   â”‚  â”‚ å¯¹æ¯”   â”‚ â”‚
â”‚  â”‚   å·¥å…·   â”‚  â”‚  å·¥å…·    â”‚  â”‚ åˆ†æå·¥å…·â”‚  â”‚ åˆ†æ   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æµå›¾

```
ç”¨æˆ·è¾“å…¥
   â”‚
   â”œâ”€â†’ æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒå·¥ä½œæµ
   â”‚       â”‚
   â”‚       â”œâ”€ æœ‰: æ¢å¤å·¥ä½œæµ
   â”‚       â”‚       â”‚
   â”‚       â”‚       â”œâ”€â†’ resume_workflow(input, run_id)
   â”‚       â”‚       â”‚       â”‚
   â”‚       â”‚       â”‚       â””â”€â†’ get_workflow_info(run_id)
   â”‚       â”‚       â”‚
   â”‚       â””â”€ æ— : å¯åŠ¨æ–°å·¥ä½œæµ
   â”‚               â”‚
   â”‚               â”œâ”€â†’ start_workflow(input)
   â”‚               â”‚       â”‚
   â”‚               â”‚       â””â”€â†’ get_workflow_info(run_id)
   â”‚
   â”œâ”€â†’ åˆ¤æ–­å·¥ä½œæµçŠ¶æ€
   â”‚       â”‚
   â”‚       â”œâ”€ interrupted (ä¸­æ–­)
   â”‚       â”‚       â”‚
   â”‚       â”‚       â””â”€â†’ è¯¢é—®ç”¨æˆ·æ›´å¤šä¿¡æ¯
   â”‚       â”‚
   â”‚       â””â”€ completed (å®Œæˆ)
   â”‚               â”‚
   â”‚               â”œâ”€â†’ æå–å‚æ•°
   â”‚               â”‚
   â”‚               â”œâ”€â†’ è°ƒç”¨å·¥å…·å‡½æ•°
   â”‚               â”‚       â”‚
   â”‚               â”‚       â”œâ”€â†’ å¤„ç†æ•°æ®
   â”‚               â”‚       â”‚
   â”‚               â”‚       â””â”€â†’ ç”Ÿæˆæ–‡ä»¶å’Œå›¾ç‰‡
   â”‚               â”‚
   â”‚               â””â”€â†’ æ ¼å¼åŒ–ç»“æœ
   â”‚
   â””â”€â†’ æ›´æ–°ç•Œé¢
           â”‚
           â”œâ”€â†’ æ›´æ–°å¯¹è¯å†å²
           â”œâ”€â†’ å±•ç¤ºå›¾ç‰‡
           â””â”€â†’ æä¾›æ–‡ä»¶ä¸‹è½½
```

### 3.3 æ¨¡å—å…³ç³»å›¾

```
WorkflowStateManager
    â”‚
    â”œâ”€ ç®¡ç†å·¥ä½œæµçŠ¶æ€
    â”‚   â””â”€ active_workflows: Dict[str, Dict]
    â”‚
    â””â”€ ç®¡ç†å¯¹è¯å†å²
        â””â”€ conversation_history: Dict[str, List[Dict]]

Tool Functions
    â”‚
    â”œâ”€ inline_compare
    â”œâ”€ statistical_analysis
    â”œâ”€ trend_analysis
    â””â”€ correlation_analysis

Gradio Interface
    â”‚
    â”œâ”€ Chatbot (å¯¹è¯ç•Œé¢)
    â”œâ”€ Gallery (å›¾ç‰‡å±•ç¤º)
    â””â”€ File (æ–‡ä»¶ä¸‹è½½)
```

---

## 4. å¼€å‘ç¯å¢ƒå‡†å¤‡

### 4.1 ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|-----|---------|---------|
| æ“ä½œç³»ç»Ÿ | Windows/Linux/macOS | ä»»æ„ |
| Python | 3.8+ | 3.10+ |
| å†…å­˜ | 2GB | 4GB+ |
| ç£ç›˜ | 500MB | 1GB+ |

### 4.2 å®‰è£…æ­¥éª¤

#### æ­¥éª¤ 1ï¼šåˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨ venv
python3 -m venv venv
source venv/bin/activate  # Linux/macOS
# æˆ–
venv\Scripts\activate  # Windows

# ä½¿ç”¨ conda
conda create -n workflow-chatbot python=3.10
conda activate workflow-chatbot
```

#### æ­¥éª¤ 2ï¼šå®‰è£…ä¾èµ–

```bash
# ä» requirements.txt å®‰è£…
pip install -r requirements.txt

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install gradio>=4.0.0
pip install Pillow>=10.0.0
```

#### æ­¥éª¤ 3ï¼šéªŒè¯å®‰è£…

```bash
# æ£€æŸ¥ Python ç‰ˆæœ¬
python3 --version

# æ£€æŸ¥å·²å®‰è£…çš„åŒ…
pip list | grep -E "gradio|Pillow"

# è¿è¡Œæµ‹è¯•
python3 workflow_chatbot.py
```

### 4.3 IDE æ¨èé…ç½®

#### VS Code é…ç½®

åˆ›å»º `.vscode/settings.json`:

```json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.linting.enabled": true,
    "python.linting.pylintEnabled": true,
    "python.formatting.provider": "black",
    "editor.formatOnSave": true,
    "python.testing.pytestEnabled": true
}
```

#### PyCharm é…ç½®

1. æ‰“å¼€é¡¹ç›®è®¾ç½®
2. è®¾ç½® Project Interpreter ä¸ºè™šæ‹Ÿç¯å¢ƒ
3. å¯ç”¨ Black ä»£ç æ ¼å¼åŒ–
4. é…ç½® Pylint ä»£ç æ£€æŸ¥

---

## 5. å¿«é€Ÿå¼€å§‹

### 5.1 Hello World ç¤ºä¾‹

åˆ›å»ºç¬¬ä¸€ä¸ªç®€å•çš„å¯¹è¯æœºå™¨äººï¼š

```python
from gradio import Interface
import gradio as gr

def simple_chatbot(message):
    """æœ€ç®€å•çš„èŠå¤©æœºå™¨äºº"""
    responses = {
        "ä½ å¥½": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ",
        "å¸®åŠ©": "æˆ‘å¯ä»¥å¸®ä½ è¿›è¡Œæ•°æ®åˆ†æå’Œå¯è§†åŒ–",
        "å†è§": "å†è§ï¼æœŸå¾…ä¸‹æ¬¡è§é¢"
    }
    return responses.get(message, "æˆ‘ä¸ç†è§£ï¼Œè¯·é‡æ–°è¾“å…¥")

# åˆ›å»ºç•Œé¢
demo = gr.Interface(
    fn=simple_chatbot,
    inputs=gr.Textbox(label="è¾“å…¥æ¶ˆæ¯"),
    outputs=gr.Textbox(label="å›å¤"),
    title="ç®€å•èŠå¤©æœºå™¨äºº"
)

demo.launch()
```

### 5.2 è¿è¡Œç¬¬ä¸€ä¸ªå·¥ä½œæµ

```python
from workflow_chatbot import (
    start_workflow,
    get_workflow_info
)

# 1. å¯åŠ¨å·¥ä½œæµ
user_input = "å¸®æˆ‘åˆ†æé”€å”®æ•°æ®"
run_id = start_workflow(user_input)
print(f"å·¥ä½œæµå·²å¯åŠ¨: {run_id}")

# 2. æŸ¥è¯¢çŠ¶æ€
info = get_workflow_info(run_id)
print(f"å·¥ä½œæµçŠ¶æ€: {info['status']}")
print(f"æ¶ˆæ¯: {info['message']}")

# 3. å¦‚æœå®Œæˆï¼Œè·å–ç»“æœ
if info['status'] == 'completed':
    data = info['data']
    print(f"è§£æçš„å‚æ•°: {data.get('parameters')}")
```

### 5.3 åˆ›å»ºè‡ªå®šä¹‰å·¥å…·

```python
from PIL import Image, ImageDraw, ImageFont
import os

def my_custom_tool(parameters: dict) -> dict:
    """
    è‡ªå®šä¹‰å·¥å…·ï¼šç”Ÿæˆç®€å•çš„æ•°æ®æŠ¥å‘Šå›¾è¡¨

    å‚æ•°:
        parameters: {
            "title": "å›¾è¡¨æ ‡é¢˜",
            "values": [10, 20, 30],
            "labels": ["A", "B", "C"]
        }
    """
    title = parameters.get("title", "æ•°æ®æŠ¥å‘Š")
    values = parameters.get("values", [])
    labels = parameters.get("labels", [])

    # åˆ›å»ºå›¾ç‰‡
    img = Image.new('RGB', (800, 600), color='white')
    draw = ImageDraw.Draw(img)

    # ç»˜åˆ¶ç®€å•çš„æŸ±çŠ¶å›¾
    max_val = max(values) if values else 1
    bar_width = 600 // len(values) if values else 100

    for i, (val, label) in enumerate(zip(values, labels)):
        x = 100 + i * bar_width
        height = (val / max_val) * 400
        y = 500 - height
        draw.rectangle([x, y, x + bar_width - 10, 500], fill='blue')

    # ä¿å­˜æ–‡ä»¶
    output_path = "outputs/custom_chart.png"
    os.makedirs("outputs", exist_ok=True)
    img.save(output_path)

    # è¿”å›ç»“æœ
    return {
        "message": f"è‡ªå®šä¹‰å·¥å…·æ‰§è¡Œå®Œæˆ: {title}",
        "result": {
            "files": [output_path],
            "images": [img]
        }
    }

# æ³¨å†Œå·¥å…·
from workflow_chatbot import TOOL_FUNCTIONS
TOOL_FUNCTIONS["my_custom_tool"] = my_custom_tool
```

---

## 6. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 6.1 WorkflowStateManagerï¼ˆçŠ¶æ€ç®¡ç†å™¨ï¼‰

#### ç±»å®šä¹‰

```python
class WorkflowStateManager:
    """ç®¡ç†å·¥ä½œæµçŠ¶æ€å’Œå¯¹è¯å†å²"""

    def __init__(self):
        self.active_workflows: Dict[str, Dict] = {}
        self.conversation_history: Dict[str, List[Dict]] = {}
```

#### æ ¸å¿ƒæ–¹æ³•

##### save_workflow_state()

```python
def save_workflow_state(self, run_id: str, state: dict):
    """
    ä¿å­˜å·¥ä½œæµçŠ¶æ€

    å‚æ•°:
        run_id: å·¥ä½œæµID
        state: {
            "status": "interrupted" | "completed",
            "message": "çŠ¶æ€æ¶ˆæ¯",
            "data": {...}
        }
    """
    self.active_workflows[run_id] = state
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
manager = WorkflowStateManager()

# ä¿å­˜çŠ¶æ€
manager.save_workflow_state("run_123", {
    "status": "interrupted",
    "message": "éœ€è¦æ›´å¤šæ•°æ®",
    "data": {"required": ["dataset1"]}
})

# è·å–çŠ¶æ€
state = manager.get_workflow_state("run_123")
print(state['status'])  # è¾“å‡º: interrupted
```

##### add_to_history()

```python
def add_to_history(self, run_id: str, role: str, content: str, metadata: dict = None):
    """
    æ·»åŠ å¯¹è¯å†å²

    å‚æ•°:
        run_id: å·¥ä½œæµID
        role: "user" æˆ– "assistant"
        content: æ¶ˆæ¯å†…å®¹
        metadata: é™„åŠ å…ƒæ•°æ®
    """
    if run_id not in self.conversation_history:
        self.conversation_history[run_id] = []

    self.conversation_history[run_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat(),
        "metadata": metadata or {}
    })
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
# æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
manager.add_to_history(
    run_id="run_123",
    role="user",
    content="åˆ†æé”€å”®æ•°æ®",
    metadata={"intent": "analysis"}
)

# æ·»åŠ åŠ©æ‰‹å›å¤
manager.add_to_history(
    run_id="run_123",
    role="assistant",
    content="å¥½çš„ï¼Œæ­£åœ¨å¯åŠ¨åˆ†ææµç¨‹"
)

# è·å–å†å²
history = manager.get_history("run_123")
for msg in history:
    print(f"{msg['role']}: {msg['content']}")
```

### 6.2 å·¥ä½œæµå‡½æ•°

#### start_workflow()

```python
def start_workflow(user_input: str) -> str:
    """
    å¯åŠ¨å·¥ä½œæµ

    å‚æ•°:
        user_input: ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥

    è¿”å›:
        run_id: å·¥ä½œæµè¿è¡ŒID

    å®ç°è¦ç‚¹:
        1. è§£æç”¨æˆ·æ„å›¾
        2. åˆ›å»ºå·¥ä½œæµå®ä¾‹
        3. æ‰§è¡Œåˆå§‹åŒ–æ­¥éª¤
        4. è¿”å›å”¯ä¸€ID
    """
    # å®é™…å®ç°ç¤ºä¾‹
    intent = parse_intent(user_input)
    workflow = create_workflow(intent)
    run_id = workflow.initialize()
    return run_id
```

#### get_workflow_info()

```python
def get_workflow_info(run_id: str) -> Dict:
    """
    è·å–å·¥ä½œæµä¿¡æ¯

    å‚æ•°:
        run_id: å·¥ä½œæµID

    è¿”å›:
        {
            "run_id": "run_123",
            "status": "interrupted" | "completed" | "running",
            "message": "çŠ¶æ€æè¿°",
            "data": {
                "parameters": {...},
                "tools": [...]
            },
            "progress": 0-100  # å¯é€‰
        }
    """
    # å®é™…å®ç°ç¤ºä¾‹
    workflow = load_workflow(run_id)
    return {
        "run_id": run_id,
        "status": workflow.get_status(),
        "message": workflow.get_status_message(),
        "data": workflow.get_results()
    }
```

#### resume_workflow()

```python
def resume_workflow(user_input: str, run_id: str) -> str:
    """
    æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ

    å‚æ•°:
        user_input: ç”¨æˆ·è¡¥å……çš„ä¿¡æ¯
        run_id: å·¥ä½œæµID

    è¿”å›:
        run_id: æ›´æ–°åçš„å·¥ä½œæµID

    å®ç°è¦ç‚¹:
        1. åŠ è½½ä¸­æ–­çš„å·¥ä½œæµ
        2. è§£æç”¨æˆ·è¾“å…¥
        3. æ›´æ–°å·¥ä½œæµå‚æ•°
        4. ç»§ç»­æ‰§è¡Œ
    """
    # å®é™…å®ç°ç¤ºä¾‹
    workflow = load_workflow(run_id)
    workflow.update_parameters(user_input)
    workflow.resume()
    return run_id
```

### 6.3 ç»“æœå¤„ç†

#### process_tool_results()

```python
def process_tool_results(tool_output: Dict, run_id: str) -> Tuple[str, List]:
    """
    å¤„ç†å·¥å…·è¾“å‡ºç»“æœ

    å‚æ•°:
        tool_output: {
            "message": "å¤„ç†æ¶ˆæ¯",
            "result": {
                "files": [...],
                "images": [...]
            }
        }
        run_id: å·¥ä½œæµID

    è¿”å›:
        (summary_text, display_items)
        - summary_text: æ ¼å¼åŒ–çš„æ‘˜è¦æ–‡æœ¬
        - display_items: Gradio ç»„ä»¶åˆ—è¡¨
    """
    # å®ç°ç»†èŠ‚è§æºç 
```

**å¤„ç†æµç¨‹ï¼š**

```
å·¥å…·è¾“å‡º
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æå–æ¶ˆæ¯        â”‚ â†’ æ·»åŠ åˆ°æ‘˜è¦
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¤„ç†å›¾ç‰‡        â”‚ â†’ è½¬æ¢ä¸º Gradio.Image
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å¤„ç†æ–‡ä»¶        â”‚ â†’ æ·»åŠ æ–‡ä»¶ä¿¡æ¯
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ·»åŠ å†å²ä¿¡æ¯    â”‚ â†’ ç»Ÿè®¡å¯¹è¯è½®æ¬¡
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
è¿”å›æ ¼å¼åŒ–ç»“æœ
```

---

## 7. API å‚è€ƒ

### 7.1 æ ¸å¿ƒå‡½æ•° API

#### start_workflow()

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|-----|------|-----|------|
| user_input | str | âœ… | ç”¨æˆ·è‡ªç„¶è¯­è¨€è¾“å…¥ |

**è¿”å›å€¼ï¼š** `str` - å·¥ä½œæµè¿è¡ŒID

**ç¤ºä¾‹ï¼š**
```python
run_id = start_workflow("åˆ†æé”€å”®æ•°æ®çš„è¶‹åŠ¿")
# è¿”å›: "run_20240126_143052"
```

#### get_workflow_info()

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|-----|------|-----|------|
| run_id | str | âœ… | å·¥ä½œæµID |

**è¿”å›å€¼ï¼š** `Dict` - å·¥ä½œæµä¿¡æ¯å­—å…¸

**å­—æ®µè¯´æ˜ï¼š**

| å­—æ®µ | ç±»å‹ | è¯´æ˜ |
|-----|------|------|
| run_id | str | å·¥ä½œæµID |
| status | str | çŠ¶æ€ï¼šinterrupted/completed/running |
| message | str | çŠ¶æ€æè¿°æ¶ˆæ¯ |
| data | dict | åŒ…å« parameters å’Œ tools |
| progress | int | è¿›åº¦ç™¾åˆ†æ¯” (0-100) |

**ç¤ºä¾‹ï¼š**
```python
info = get_workflow_info("run_20240126_143052")
# {
#     "run_id": "run_20240126_143052",
#     "status": "completed",
#     "message": "åˆ†æå®Œæˆ",
#     "data": {
#         "parameters": {"method": "linear_regression"},
#         "tools": ["trend_analysis"]
#     }
# }
```

#### resume_workflow()

| å‚æ•° | ç±»å‹ | å¿…å¡« | è¯´æ˜ |
|-----|------|-----|------|
| user_input | str | âœ… | ç”¨æˆ·è¡¥å……ä¿¡æ¯ |
| run_id | str | âœ… | å·¥ä½œæµID |

**è¿”å›å€¼ï¼š** `str` - æ›´æ–°åçš„å·¥ä½œæµID

**ç¤ºä¾‹ï¼š**
```python
new_run_id = resume_workflow("ä½¿ç”¨ç§»åŠ¨å¹³å‡æ³•", "run_20240126_143052")
# è¿”å›: "run_20240126_143052"
```

### 7.2 å·¥å…·å‡½æ•° API è§„èŒƒ

#### æ ‡å‡†ç­¾å

```python
def tool_function(parameters: dict) -> dict
```

#### å‚æ•°æ ¼å¼

```python
{
    "param1": "value1",
    "param2": "value2",
    ...
}
```

#### è¿”å›å€¼æ ¼å¼

```python
{
    "message": str,           # æ‰§è¡Œç»“æœæ¶ˆæ¯
    "result": {
        "files": List[str],    # æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        "images": List[Image] # PIL.Image å¯¹è±¡åˆ—è¡¨
    }
}
```

#### ç¤ºä¾‹å·¥å…·å‡½æ•°

```python
def example_tool(parameters: dict) -> dict:
    """
    ç¤ºä¾‹å·¥å…·å‡½æ•°

    å‚æ•°:
        parameters: {
            "input_file": str,      # è¾“å…¥æ–‡ä»¶è·¯å¾„
            "output_dir": str,      # è¾“å‡ºç›®å½•
            "option": str           # é€‰é¡¹
        }

    è¿”å›:
        {
            "message": "å¤„ç†å®Œæˆ",
            "result": {
                "files": ["path/to/output1.csv", "path/to/output2.png"],
                "images": [PIL.Image, PIL.Image]
            }
        }
    """
    # å®ç°é€»è¾‘...
    pass
```

### 7.3 Gradio ç»„ä»¶ API

#### Chatbot

```python
gr.Chatbot(
    label="å¯¹è¯å†å²",
    height=500,
    bubble_full_width=False,
    avatar_images=(user_avatar, bot_avatar)
)
```

#### Gallery

```python
gr.Gallery(
    label="ç”Ÿæˆçš„å›¾è¡¨",
    columns=2,
    rows=3,
    height="auto",
    object_fit="contain"
)
```

#### File

```python
gr.File(
    label="ä¸‹è½½æ–‡ä»¶",
    file_count="multiple",
    interactive=False
)
```

---

## 8. å®æˆ˜æ•™ç¨‹

### 8.1 æ•™ç¨‹ 1ï¼šåˆ›å»ºç®€å•çš„åˆ†æå·¥å…·

#### ç›®æ ‡

åˆ›å»ºä¸€ä¸ªå·¥å…·ï¼Œè¯»å–CSVæ–‡ä»¶å¹¶ç”ŸæˆåŸºæœ¬çš„ç»Ÿè®¡æŠ¥å‘Šã€‚

#### æ­¥éª¤

**æ­¥éª¤ 1ï¼šåˆ›å»ºå·¥å…·å‡½æ•°**

```python
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import io

def basic_statistics_tool(parameters: dict) -> dict:
    """
    åŸºæœ¬ç»Ÿè®¡åˆ†æå·¥å…·

    å‚æ•°:
        parameters: {
            "csv_path": str,      # CSVæ–‡ä»¶è·¯å¾„
            "columns": List[str]  # è¦åˆ†æçš„åˆ—
        }
    """
    csv_path = parameters.get("csv_path")
    columns = parameters.get("columns", [])

    # 1. è¯»å–æ•°æ®
    df = pd.read_csv(csv_path)

    # 2. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    if not columns:
        columns = df.select_dtypes(include=['number']).columns.tolist()

    stats = df[columns].describe()

    # 3. ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    output_dir = "outputs"
    import os
    os.makedirs(output_dir, exist_ok=True)

    stats_path = f"{output_dir}/statistics_report.csv"
    stats.to_csv(stats_path)

    # 4. ç”Ÿæˆå¯è§†åŒ–
    plt.figure(figsize=(12, 6))

    for i, col in enumerate(columns[:4], 1):
        plt.subplot(2, 2, i)
        df[col].hist(bins=20)
        plt.title(f'{col} åˆ†å¸ƒ')

    plt.tight_layout()

    # ä¿å­˜ä¸ºå›¾ç‰‡å¯¹è±¡
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=100)
    buf.seek(0)
    img = Image.open(buf)

    chart_path = f"{output_dir}/distribution_charts.png"
    img.save(chart_path)

    # 5. è¿”å›ç»“æœ
    return {
        "message": f"ç»Ÿè®¡åˆ†æå®Œæˆï¼åˆ†æäº† {len(columns)} ä¸ªæ•°å€¼åˆ—",
        "result": {
            "files": [stats_path, chart_path],
            "images": [img]
        }
    }
```

**æ­¥éª¤ 2ï¼šæ³¨å†Œå·¥å…·**

```python
from workflow_chatbot import TOOL_FUNCTIONS

TOOL_FUNCTIONS["basic_statistics"] = basic_statistics_tool
```

**æ­¥éª¤ 3ï¼šæµ‹è¯•å·¥å…·**

```python
# åˆ›å»ºæµ‹è¯•æ•°æ®
import pandas as pd
import os

os.makedirs("outputs", exist_ok=True)

# ç”Ÿæˆæµ‹è¯•CSV
test_data = pd.DataFrame({
    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'B': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],
    'C': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]
})
test_data.to_csv('outputs/test_data.csv', index=False)

# æµ‹è¯•å·¥å…·
result = basic_statistics_tool({
    "csv_path": "outputs/test_data.csv",
    "columns": ["A", "B", "C"]
})

print(result['message'])
print(f"ç”Ÿæˆæ–‡ä»¶: {result['result']['files']}")
```

### 8.2 æ•™ç¨‹ 2ï¼šå®ç°å¤šæ­¥éª¤å·¥ä½œæµ

#### ç›®æ ‡

åˆ›å»ºä¸€ä¸ªéœ€è¦å¤šä¸ªæ­¥éª¤æ‰èƒ½å®Œæˆçš„å¤æ‚å·¥ä½œæµã€‚

#### åœºæ™¯

ç”¨æˆ·è¯·æ±‚è¿›è¡Œæ•°æ®å¯¹æ¯”åˆ†æï¼Œå·¥ä½œæµéœ€è¦ï¼š
1. è¯¢é—®ç”¨æˆ·å¯¹æ¯”çš„æ–¹æ³•
2. è¯¢é—®ç”¨æˆ·éœ€è¦å¯è§†åŒ–å“ªäº›ç»´åº¦
3. æ‰§è¡Œåˆ†æå¹¶ç”Ÿæˆç»“æœ

#### å®ç°

**æ­¥éª¤ 1ï¼šå®šä¹‰å·¥ä½œæµçŠ¶æ€**

```python
class ComparisonWorkflow:
    """å¯¹æ¯”åˆ†æå·¥ä½œæµ"""

    def __init__(self, run_id: str):
        self.run_id = run_id
        self.state = "step1_ask_method"
        self.data = {
            "method": None,
            "dimensions": None,
            "datasets": None
        }

    def process(self, user_input: str) -> dict:
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""

        if self.state == "step1_ask_method":
            return self._handle_step1(user_input)
        elif self.state == "step2_ask_dimensions":
            return self._handle_step2(user_input)
        elif self.state == "step3_complete":
            return self._handle_step3()
        else:
            return {"status": "error", "message": "æœªçŸ¥çŠ¶æ€"}

    def _handle_step1(self, user_input: str) -> dict:
        """å¤„ç†ç¬¬ä¸€æ­¥ï¼šè¯¢é—®å¯¹æ¯”æ–¹æ³•"""
        # ä¿å­˜ç”¨æˆ·è¾“å…¥
        self.data["method"] = user_input

        # è½¬åˆ°ä¸‹ä¸€æ­¥
        self.state = "step2_ask_dimensions"

        return {
            "status": "interrupted",
            "message": f"å¥½çš„ï¼Œå°†ä½¿ç”¨ {user_input} è¿›è¡Œå¯¹æ¯”ã€‚è¯·é—®éœ€è¦å¯¹æ¯”å“ªäº›ç»´åº¦ï¼Ÿ\n"
                      "ä¾‹å¦‚ï¼šé”€å”®é¢ã€åˆ©æ¶¦ç‡ã€å®¢æˆ·æ•°é‡ç­‰",
            "data": {}
        }

    def _handle_step2(self, user_input: str) -> dict:
        """å¤„ç†ç¬¬äºŒæ­¥ï¼šè¯¢é—®å¯è§†åŒ–ç»´åº¦"""
        # ä¿å­˜ç»´åº¦ä¿¡æ¯
        self.data["dimensions"] = user_input

        # è½¬åˆ°å®ŒæˆçŠ¶æ€
        self.state = "step3_complete"

        return {
            "status": "interrupted",
            "message": f"æ˜ç™½ï¼å°†å¯¹æ¯” {self.data['dimensions']} ç»´åº¦ã€‚\n"
                      "å·¥ä½œæµå³å°†å®Œæˆåˆ†æ...",
            "data": {}
        }

    def _handle_step3(self) -> dict:
        """å¤„ç†ç¬¬ä¸‰æ­¥ï¼šå®Œæˆåˆ†æ"""
        # æ‰§è¡Œå®é™…çš„åˆ†æé€»è¾‘
        self.state = "completed"

        return {
            "status": "completed",
            "message": "å¯¹æ¯”åˆ†æå®Œæˆï¼",
            "data": {
                "parameters": self.data,
                "tools": ["inline_compare"]
            }
        }
```

**æ­¥éª¤ 2ï¼šé›†æˆåˆ°ç³»ç»Ÿ**

```python
# ä¿®æ”¹ start_workflow
workflows = {}  # å…¨å±€å·¥ä½œæµå­˜å‚¨

def start_workflow(user_input: str) -> str:
    """å¯åŠ¨å¯¹æ¯”åˆ†æå·¥ä½œæµ"""
    run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    workflow = ComparisonWorkflow(run_id)
    workflows[run_id] = workflow

    # è·å–åˆå§‹å“åº”
    response = workflow.process(user_input)

    return run_id

# ä¿®æ”¹ get_workflow_info
def get_workflow_info(run_id: str) -> dict:
    """è·å–å·¥ä½œæµä¿¡æ¯"""
    workflow = workflows.get(run_id)
    if not workflow:
        return {"status": "error", "message": "å·¥ä½œæµä¸å­˜åœ¨"}

    return {
        "run_id": run_id,
        "status": workflow.state if workflow.state != "step3_complete" else "completed",
        "message": "å·¥ä½œæµè¿è¡Œä¸­",
        "data": workflow.data
    }

# ä¿®æ”¹ resume_workflow
def resume_workflow(user_input: str, run_id: str) -> str:
    """æ¢å¤å·¥ä½œæµ"""
    workflow = workflows.get(run_id)
    if not workflow:
        raise ValueError("å·¥ä½œæµä¸å­˜åœ¨")

    response = workflow.process(user_input)
    return run_id
```

**æ­¥éª¤ 3ï¼šæµ‹è¯•å·¥ä½œæµ**

```python
# æ¨¡æ‹Ÿå®Œæ•´å¯¹è¯
print("=== å¯¹è¯å¼€å§‹ ===")

# ç¬¬ä¸€è½®
user_input1 = "å¸®æˆ‘å¯¹æ¯”Q1å’ŒQ4çš„é”€å”®æ•°æ®"
run_id = start_workflow(user_input1)
info1 = get_workflow_info(run_id)
print(f"\nç”¨æˆ·: {user_input1}")
print(f"åŠ©æ‰‹: {info1['message']}")

# ç¬¬äºŒè½®
user_input2 = "ä½¿ç”¨tæ£€éªŒæ–¹æ³•"
resume_workflow(user_input2, run_id)
info2 = get_workflow_info(run_id)
print(f"\nç”¨æˆ·: {user_input2}")
print(f"åŠ©æ‰‹: {info2['message']}")

# ç¬¬ä¸‰è½®
user_input3 = "å¯¹æ¯”é”€å”®é¢å’Œå®¢æˆ·æ•°"
resume_workflow(user_input3, run_id)
info3 = get_workflow_info(run_id)
print(f"\nç”¨æˆ·: {user_input3}")
print(f"åŠ©æ‰‹: {info3['message']}")
```

### 8.3 æ•™ç¨‹ 3ï¼šæ·»åŠ æ•°æ®æŒä¹…åŒ–

#### ç›®æ ‡

å°†å·¥ä½œæµçŠ¶æ€å’Œå¯¹è¯å†å²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå®ç°è·¨ä¼šè¯æŒä¹…åŒ–ã€‚

#### å®ç°æ–¹æ¡ˆï¼šä½¿ç”¨ SQLite

**æ­¥éª¤ 1ï¼šåˆ›å»ºæ•°æ®åº“æ¨¡å‹**

```python
import sqlite3
from datetime import datetime
import json

class WorkflowDatabase:
    """å·¥ä½œæµæ•°æ®åº“ç®¡ç†"""

    def __init__(self, db_path="workflow.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # åˆ›å»ºå·¥ä½œæµè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS workflows (
                run_id TEXT PRIMARY KEY,
                status TEXT NOT NULL,
                state_data TEXT,
                created_at TEXT,
                updated_at TEXT
            )
        """)

        # åˆ›å»ºå¯¹è¯å†å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS conversation_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                run_id TEXT NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                metadata TEXT,
                timestamp TEXT,
                FOREIGN KEY (run_id) REFERENCES workflows (run_id)
            )
        """)

        conn.commit()
        conn.close()

    def save_workflow(self, run_id: str, status: str, state_data: dict):
        """ä¿å­˜å·¥ä½œæµçŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        now = datetime.now().isoformat()

        cursor.execute("""
            INSERT OR REPLACE INTO workflows
            (run_id, status, state_data, created_at, updated_at)
            VALUES (?, ?, ?, COALESCE((SELECT created_at FROM workflows WHERE run_id=?), ?), ?)
        """, (run_id, status, json.dumps(state_data), run_id, now, now))

        conn.commit()
        conn.close()

    def get_workflow(self, run_id: str) -> dict:
        """è·å–å·¥ä½œæµ"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT status, state_data FROM workflows WHERE run_id=?
        """, (run_id,))

        row = cursor.fetchone()
        conn.close()

        if row:
            return {
                "status": row[0],
                "state_data": json.loads(row[1])
            }
        return None

    def save_message(self, run_id: str, role: str, content: str, metadata: dict = None):
        """ä¿å­˜å¯¹è¯æ¶ˆæ¯"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO conversation_history
            (run_id, role, content, metadata, timestamp)
            VALUES (?, ?, ?, ?, ?)
        """, (run_id, role, content, json.dumps(metadata or {}), datetime.now().isoformat()))

        conn.commit()
        conn.close()

    def get_history(self, run_id: str) -> list:
        """è·å–å¯¹è¯å†å²"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT role, content, metadata, timestamp
            FROM conversation_history
            WHERE run_id=?
            ORDER BY timestamp ASC
        """, (run_id,))

        rows = cursor.fetchall()
        conn.close()

        return [
            {
                "role": row[0],
                "content": row[1],
                "metadata": json.loads(row[2]),
                "timestamp": row[3]
            }
            for row in rows
        ]
```

**æ­¥éª¤ 2ï¼šé›†æˆåˆ°çŠ¶æ€ç®¡ç†å™¨**

```python
class PersistentWorkflowManager:
    """æ”¯æŒæŒä¹…åŒ–çš„å·¥ä½œæµç®¡ç†å™¨"""

    def __init__(self):
        self.db = WorkflowDatabase()
        self.active_workflows = {}

    def save_workflow_state(self, run_id: str, state: dict):
        """ä¿å­˜å·¥ä½œæµçŠ¶æ€ï¼ˆåŒæ—¶ä¿å­˜åˆ°å†…å­˜å’Œæ•°æ®åº“ï¼‰"""
        self.active_workflows[run_id] = state
        self.db.save_workflow(run_id, state['status'], state)

    def get_workflow_state(self, run_id: str) -> dict:
        """è·å–å·¥ä½œæµçŠ¶æ€ï¼ˆä¼˜å…ˆä»å†…å­˜ï¼Œå¦åˆ™ä»æ•°æ®åº“ï¼‰"""
        if run_id in self.active_workflows:
            return self.active_workflows[run_id]

        # ä»æ•°æ®åº“åŠ è½½
        data = self.db.get_workflow(run_id)
        if data:
            state = data['state_data']
            self.active_workflows[run_id] = state
            return state

        return None

    def add_to_history(self, run_id: str, role: str, content: str, metadata: dict = None):
        """æ·»åŠ å¯¹è¯å†å²"""
        self.db.save_message(run_id, role, content, metadata)

    def get_history(self, run_id: str) -> list:
        """è·å–å¯¹è¯å†å²"""
        return self.db.get_history(run_id)

    def load_interrupted_workflows(self):
        """åŠ è½½æ‰€æœ‰ä¸­æ–­çš„å·¥ä½œæµ"""
        conn = self.db.db
        import sqlite3
        conn = sqlite3.connect(self.db.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT run_id, state_data FROM workflows WHERE status='interrupted'
        """)

        rows = cursor.fetchall()
        conn.close()

        for run_id, state_data_json in rows:
            state = json.loads(state_data_json)
            self.active_workflows[run_id] = state

        return len(rows)
```

**æ­¥éª¤ 3ï¼šä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨**

```python
# æ›¿æ¢åŸæœ‰çš„ç®¡ç†å™¨
workflow_manager = PersistentWorkflowManager()

# å¯åŠ¨æ—¶åŠ è½½ä¸­æ–­çš„å·¥ä½œæµ
count = workflow_manager.load_interrupted_workflows()
print(f"åŠ è½½äº† {count} ä¸ªä¸­æ–­çš„å·¥ä½œæµ")

# æ­£å¸¸ä½¿ç”¨
run_id = start_workflow("åˆ†æé”€å”®æ•°æ®")
# ... ç³»ç»Ÿé‡å¯ ...
# run_id ä»ç„¶å¯ä»¥ä»æ•°æ®åº“ä¸­æ¢å¤
state = workflow_manager.get_workflow_state(run_id)
```

---

## 9. é«˜çº§åŠŸèƒ½

### 9.1 å¹¶å‘å·¥ä½œæµå¤„ç†

#### é—®é¢˜

å½“å¤šä¸ªç”¨æˆ·åŒæ—¶ä½¿ç”¨ç³»ç»Ÿæ—¶ï¼Œå¦‚ä½•é¿å…å·¥ä½œæµå†²çªï¼Ÿ

#### è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨çº¿ç¨‹é”

```python
import threading

class ThreadSafeWorkflowManager:
    """çº¿ç¨‹å®‰å…¨çš„å·¥ä½œæµç®¡ç†å™¨"""

    def __init__(self):
        self.active_workflows = {}
        self.conversation_history = {}
        self.lock = threading.Lock()

    def save_workflow_state(self, run_id: str, state: dict):
        """çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€ä¿å­˜"""
        with self.lock:
            self.active_workflows[run_id] = state

    def get_workflow_state(self, run_id: str) -> dict:
        """çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€è·å–"""
        with self.lock:
            return self.active_workflows.get(run_id)

    def add_to_history(self, run_id: str, role: str, content: str, metadata: dict = None):
        """çº¿ç¨‹å®‰å…¨çš„å†å²æ·»åŠ """
        with self.lock:
            if run_id not in self.conversation_history:
                self.conversation_history[run_id] = []

            self.conversation_history[run_id].append({
                "role": role,
                "content": content,
                "timestamp": datetime.now().isoformat(),
                "metadata": metadata or {}
            })
```

### 9.2 å·¥ä½œæµè¶…æ—¶å¤„ç†

#### éœ€æ±‚

è‡ªåŠ¨æ¸…ç†é•¿æ—¶é—´æœªæ´»åŠ¨çš„å·¥ä½œæµã€‚

#### å®ç°

```python
import time
from datetime import datetime, timedelta

class WorkflowManagerWithTimeout:
    """æ”¯æŒè¶…æ—¶çš„å·¥ä½œæµç®¡ç†å™¨"""

    def __init__(self, timeout_minutes=30):
        self.active_workflows = {}
        self.conversation_history = {}
        self.timeout = timedelta(minutes=timeout_minutes)

    def save_workflow_state(self, run_id: str, state: dict):
        """ä¿å­˜çŠ¶æ€æ—¶è®°å½•æ—¶é—´æˆ³"""
        state['last_activity'] = datetime.now().isoformat()
        self.active_workflows[run_id] = state

    def cleanup_expired_workflows(self):
        """æ¸…ç†è¿‡æœŸçš„å·¥ä½œæµ"""
        now = datetime.now()
        expired = []

        for run_id, state in self.active_workflows.items():
            last_activity = datetime.fromisoformat(state['last_activity'])
            if now - last_activity > self.timeout:
                expired.append(run_id)

        for run_id in expired:
            del self.active_workflows[run_id]
            if run_id in self.conversation_history:
                del self.conversation_history[run_id]

        return len(expired)

    # å®šæ—¶æ¸…ç†
    def start_cleanup_scheduler(self, interval_seconds=300):
        """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡"""
        import threading

        def cleanup_loop():
            while True:
                count = self.cleanup_expired_workflows()
                if count > 0:
                    print(f"æ¸…ç†äº† {count} ä¸ªè¿‡æœŸå·¥ä½œæµ")
                time.sleep(interval_seconds)

        thread = threading.Thread(target=cleanup_loop, daemon=True)
        thread.start()
```

### 9.3 æµå¼è¾“å‡ºæ”¯æŒ

#### éœ€æ±‚

å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Œå®æ—¶æ˜¾ç¤ºè¿›åº¦å’Œä¸­é—´ç»“æœã€‚

#### å®ç°

```python
import queue
import threading

class StreamingWorkflow:
    """æ”¯æŒæµå¼è¾“å‡ºçš„å·¥ä½œæµ"""

    def __init__(self, run_id: str):
        self.run_id = run_id
        self.output_queue = queue.Queue()

    def run_with_streaming(self, parameters: dict):
        """è¿è¡Œå·¥ä½œæµå¹¶æµå¼è¾“å‡º"""
        def worker():
            # æ­¥éª¤ 1
            self.output_queue.put({"progress": 10, "message": "æ­£åœ¨åŠ è½½æ•°æ®..."})
            time.sleep(1)

            # æ­¥éª¤ 2
            self.output_queue.put({"progress": 30, "message": "æ­£åœ¨å¤„ç†æ•°æ®..."})
            time.sleep(2)

            # æ­¥éª¤ 3
            self.output_queue.put({"progress": 60, "message": "æ­£åœ¨ç”Ÿæˆå›¾è¡¨..."})
            time.sleep(1)

            # å®Œæˆ
            self.output_queue.put({"progress": 100, "message": "å®Œæˆï¼", "complete": True})

        thread = threading.Thread(target=worker)
        thread.start()

        return thread

    def get_streaming_output(self):
        """è·å–æµå¼è¾“å‡º"""
        while True:
            try:
                output = self.output_queue.get(timeout=0.1)
                yield output
                if output.get('complete'):
                    break
            except queue.Empty:
                continue

# åœ¨ Gradio ä¸­ä½¿ç”¨
def create_streaming_interface():
    """åˆ›å»ºæ”¯æŒæµå¼è¾“å‡ºçš„ç•Œé¢"""
    def process_with_streaming(user_input, history):
        run_id = start_workflow(user_input)
        workflow = StreamingWorkflow(run_id)

        workflow.run_with_streaming({})

        # æ”¶é›†æ‰€æœ‰è¾“å‡º
        outputs = []
        for output in workflow.get_streaming_output():
            outputs.append(f"{output['message']} ({output['progress']}%)")
            # å®æ—¶æ›´æ–°ç•Œé¢
            yield history + [[user_input, "\n".join(outputs)]], []

        # å®Œæˆåè·å–æœ€ç»ˆç»“æœ
        final_info = get_workflow_info(run_id)
        # ...

    demo = gr.Interface(
        fn=process_with_streaming,
        inputs=[gr.Textbox(), gr.Chatbot()],
        outputs=[gr.Chatbot(), gr.Gallery()]
    )
    return demo
```

### 9.4 å·¥ä½œæµç‰ˆæœ¬æ§åˆ¶

#### éœ€æ±‚

è·Ÿè¸ªå·¥ä½œæµçš„ç‰ˆæœ¬å˜åŒ–ï¼Œæ”¯æŒå›æ»šã€‚

#### å®ç°

```python
class VersionedWorkflowManager:
    """æ”¯æŒç‰ˆæœ¬æ§åˆ¶çš„å·¥ä½œæµç®¡ç†å™¨"""

    def __init__(self):
        self.workflows = {}
        self.versions = {}

    def save_workflow_version(self, run_id: str, state: dict, version_tag: str = None):
        """ä¿å­˜å·¥ä½œæµç‰ˆæœ¬"""
        if run_id not in self.versions:
            self.versions[run_id] = []

        version = {
            "version": len(self.versions[run_id]) + 1,
            "tag": version_tag,
            "state": state.copy(),
            "timestamp": datetime.now().isoformat()
        }

        self.versions[run_id].append(version)
        self.workflows[run_id] = state

        return version['version']

    def rollback_to_version(self, run_id: str, version_number: int):
        """å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬"""
        if run_id not in self.versions:
            raise ValueError("å·¥ä½œæµä¸å­˜åœ¨")

        for version in self.versions[run_id]:
            if version['version'] == version_number:
                self.workflows[run_id] = version['state'].copy()
                return version

        raise ValueError("ç‰ˆæœ¬ä¸å­˜åœ¨")

    def get_version_history(self, run_id: str) -> list:
        """è·å–ç‰ˆæœ¬å†å²"""
        return self.versions.get(run_id, [])

# ä½¿ç”¨ç¤ºä¾‹
manager = VersionedWorkflowManager()

# ä¿å­˜ä¸åŒç‰ˆæœ¬
manager.save_workflow_version("run_123", {"step": 1}, "åˆå§‹ç‰ˆæœ¬")
manager.save_workflow_version("run_123", {"step": 2}, "å¤„ç†ä¸­")
manager.save_workflow_version("run_123", {"step": 3}, "å®Œæˆ")

# æŸ¥çœ‹å†å²
history = manager.get_version_history("run_123")
for v in history:
    print(f"ç‰ˆæœ¬ {v['version']}: {v['tag']} - {v['timestamp']}")

# å›æ»š
manager.rollback_to_version("run_123", 2)
```

---

## 10. éƒ¨ç½²æŒ‡å—

### 10.1 æœ¬åœ°éƒ¨ç½²

#### å¼€å‘ç¯å¢ƒ

```bash
# 1. å…‹éš†æˆ–åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir workflow-chatbot
cd workflow-chatbot

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. è¿è¡Œåº”ç”¨
python workflow_chatbot.py
```

è®¿é—®ï¼š`http://localhost:7860`

### 10.2 Docker éƒ¨ç½²

#### åˆ›å»º Dockerfile

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£… Python ä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY workflow_chatbot.py .
COPY outputs/ ./outputs/

# æš´éœ²ç«¯å£
EXPOSE 7860

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1

# å¯åŠ¨åº”ç”¨
CMD ["python", "workflow_chatbot.py"]
```

#### åˆ›å»º .dockerignore

```
.git
venv
__pycache__
*.pyc
*.pyo
*.pyd
outputs/*
!outputs/.gitkeep
```

#### æ„å»ºå’Œè¿è¡Œ

```bash
# æ„å»ºé•œåƒ
docker build -t workflow-chatbot:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name chatbot \
  -p 7860:7860 \
  -v $(pwd)/outputs:/app/outputs \
  workflow-chatbot:latest

# æŸ¥çœ‹æ—¥å¿—
docker logs -f chatbot
```

### 10.3 äº‘æœåŠ¡éƒ¨ç½²

#### Hugging Face Spaces

1. **åˆ›å»ºç©ºé—´**
   - è®¿é—® https://huggingface.co/spaces
   - ç‚¹å‡» "Create new Space"
   - é€‰æ‹© "Gradio" SDK

2. **ä¸Šä¼ æ–‡ä»¶**
   ```bash
   git clone https://huggingface.co/spaces/your-username/workflow-chatbot
   cd workflow-chatbot

   # å¤åˆ¶æ–‡ä»¶
   cp workflow_chatbot.py .
   cp requirements.txt .

   git add .
   git commit -m "Initial commit"
   git push
   ```

3. **requirements.txt**
   ```txt
   gradio>=4.0.0
   Pillow>=10.0.0
   pandas
   matplotlib
   ```

#### AWS EC2

```bash
# 1. å¯åŠ¨ EC2 å®ä¾‹ï¼ˆé€‰æ‹© Ubuntuï¼‰

# 2. è¿æ¥åˆ°å®ä¾‹
ssh -i your-key.pem ubuntu@your-ec2-ip

# 3. å®‰è£…ä¾èµ–
sudo apt update
sudo apt install -y python3-pip python3-venv

# 4. è®¾ç½®åº”ç”¨
git clone your-repo
cd workflow-chatbot
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 5. ä½¿ç”¨ systemd æœåŠ¡
sudo nano /etc/systemd/system/chatbot.service
```

**æœåŠ¡é…ç½®æ–‡ä»¶ï¼š**

```ini
[Unit]
Description=Workflow Chatbot
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/workflow-chatbot
Environment="PATH=/home/ubuntu/workflow-chatbot/venv/bin"
ExecStart=/home/ubuntu/workflow-chatbot/venv/bin/python workflow_chatbot.py
Restart=always

[Install]
WantedBy=multi-user.target
```

å¯åŠ¨æœåŠ¡ï¼š

```bash
sudo systemctl start chatbot
sudo systemctl enable chatbot
sudo systemctl status chatbot
```

### 10.4 Nginx åå‘ä»£ç†

```nginx
# /etc/nginx/sites-available/chatbot

server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:7860;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_read_timeout 86400;
    }
}
```

å¯ç”¨é…ç½®ï¼š

```bash
sudo ln -s /etc/nginx/sites-available/chatbot /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

---

## 11. æœ€ä½³å®è·µ

### 11.1 ä»£ç ç»„ç»‡

#### æ¨èçš„é¡¹ç›®ç»“æ„

```
workflow-chatbot/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py         # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ constants.py        # å¸¸é‡å®šä¹‰
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ workflow.py         # å·¥ä½œæµæ ¸å¿ƒ
â”‚   â”œâ”€â”€ state_manager.py    # çŠ¶æ€ç®¡ç†
â”‚   â””â”€â”€ exceptions.py       # è‡ªå®šä¹‰å¼‚å¸¸
â”‚
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py             # å·¥å…·åŸºç±»
â”‚   â”œâ”€â”€ statistical.py      # ç»Ÿè®¡åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ visualization.py    # å¯è§†åŒ–å·¥å…·
â”‚   â””â”€â”€ comparison.py       # å¯¹æ¯”åˆ†æå·¥å…·
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ workflow_api.py     # å·¥ä½œæµAPI
â”‚   â””â”€â”€ tool_api.py         # å·¥å…·API
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py              # Gradioåº”ç”¨
â”‚   â””â”€â”€ components.py       # UIç»„ä»¶
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py           # æ—¥å¿—å·¥å…·
â”‚   â”œâ”€â”€ validators.py       # æ•°æ®éªŒè¯
â”‚   â””â”€â”€ helpers.py          # è¾…åŠ©å‡½æ•°
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_workflow.py
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â””â”€â”€ test_integration.py
â”‚
â”œâ”€â”€ outputs/                # è¾“å‡ºç›®å½•
â”œâ”€â”€ logs/                   # æ—¥å¿—ç›®å½•
â””â”€â”€ data/                   # æµ‹è¯•æ•°æ®
```

### 11.2 é”™è¯¯å¤„ç†

#### å®šä¹‰è‡ªå®šä¹‰å¼‚å¸¸

```python
# core/exceptions.py

class WorkflowError(Exception):
    """å·¥ä½œæµåŸºç¡€å¼‚å¸¸"""
    pass

class WorkflowNotFoundError(WorkflowError):
    """å·¥ä½œæµä¸å­˜åœ¨"""
    pass

class WorkflowInterruptedError(WorkflowError):
    """å·¥ä½œæµè¢«ä¸­æ–­"""
    pass

class ToolExecutionError(WorkflowError):
    """å·¥å…·æ‰§è¡Œå¤±è´¥"""
    pass

class InvalidParameterError(WorkflowError):
    """æ— æ•ˆå‚æ•°"""
    pass
```

#### ä½¿ç”¨å¼‚å¸¸å¤„ç†

```python
def process_user_message(user_input: str, history: list):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œå¸¦å®Œæ•´é”™è¯¯å¤„ç†"""

    try:
        # éªŒè¯è¾“å…¥
        if not user_input or not user_input.strip():
            raise InvalidParameterError("ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º")

        # å¯åŠ¨æˆ–æ¢å¤å·¥ä½œæµ
        try:
            run_id = get_or_create_run_id()
        except Exception as e:
            raise WorkflowError(f"å·¥ä½œæµåˆå§‹åŒ–å¤±è´¥: {str(e)}")

        # å¤„ç†å·¥ä½œæµ
        workflow_info = get_workflow_info(run_id)

        if workflow_info['status'] == 'interrupted':
            response = handle_interrupted(workflow_info, user_input)
        elif workflow_info['status'] == 'completed':
            response = handle_completed(workflow_info)
        else:
            raise WorkflowError(f"æœªçŸ¥çŠ¶æ€: {workflow_info['status']}")

        return response

    except InvalidParameterError as e:
        return f"âŒ è¾“å…¥é”™è¯¯: {str(e)}"
    except WorkflowNotFoundError as e:
        return f"âš ï¸ å·¥ä½œæµä¸å­˜åœ¨ï¼Œè¯·é‡æ–°å¼€å§‹"
    except WorkflowInterruptedError as e:
        return f"â¸ï¸ å·¥ä½œæµå·²æš‚åœ: {str(e)}"
    except ToolExecutionError as e:
        return f"ğŸ”§ å·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
    except Exception as e:
        # è®°å½•æœªé¢„æœŸçš„é”™è¯¯
        logger.error(f"æœªé¢„æœŸçš„é”™è¯¯: {str(e)}", exc_info=True)
        return "âŒ ç³»ç»Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
```

### 11.3 æ—¥å¿—è®°å½•

#### é…ç½®æ—¥å¿—ç³»ç»Ÿ

```python
# utils/logger.py

import logging
import sys
from pathlib import Path

def setup_logger(name: str, log_file: str = None, level=logging.INFO):
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""

    logger = logging.getLogger(name)
    logger.setLevel(level)

    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

    # æ–‡ä»¶å¤„ç†å™¨
    if log_file:
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)

        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger

# ä½¿ç”¨ç¤ºä¾‹
logger = setup_logger('workflow', 'logs/workflow.log')
```

#### åœ¨ä»£ç ä¸­ä½¿ç”¨æ—¥å¿—

```python
from utils.logger import logger

def start_workflow(user_input: str) -> str:
    """å¯åŠ¨å·¥ä½œæµ"""

    logger.info(f"å¯åŠ¨å·¥ä½œæµ - ç”¨æˆ·è¾“å…¥: {user_input}")

    try:
        run_id = create_workflow(user_input)
        logger.info(f"å·¥ä½œæµåˆ›å»ºæˆåŠŸ - runID: {run_id}")
        return run_id

    except Exception as e:
        logger.error(f"å·¥ä½œæµåˆ›å»ºå¤±è´¥: {str(e)}", exc_info=True)
        raise
```

### 11.4 å•å…ƒæµ‹è¯•

#### æµ‹è¯•å·¥ä½œæµå‡½æ•°

```python
# tests/test_workflow.py

import pytest
from core.workflow import start_workflow, get_workflow_info

class TestWorkflow:
    """å·¥ä½œæµæµ‹è¯•å¥—ä»¶"""

    def test_start_workflow(self):
        """æµ‹è¯•å¯åŠ¨å·¥ä½œæµ"""
        user_input = "åˆ†æé”€å”®æ•°æ®"
        run_id = start_workflow(user_input)

        assert run_id is not None
        assert run_id.startswith("run_")

    def test_get_workflow_info(self):
        """æµ‹è¯•è·å–å·¥ä½œæµä¿¡æ¯"""
        run_id = start_workflow("æµ‹è¯•")
        info = get_workflow_info(run_id)

        assert "run_id" in info
        assert "status" in info
        assert info["run_id"] == run_id

    def test_invalid_run_id(self):
        """æµ‹è¯•æ— æ•ˆçš„ runID"""
        with pytest.raises(WorkflowNotFoundError):
            get_workflow_info("invalid_run_id")
```

#### æµ‹è¯•å·¥å…·å‡½æ•°

```python
# tests/test_tools.py

import pytest
from tools.statistical import statistical_analysis
from PIL import Image

class TestTools:
    """å·¥å…·å‡½æ•°æµ‹è¯•å¥—ä»¶"""

    def test_statistical_analysis(self):
        """æµ‹è¯•ç»Ÿè®¡åˆ†æå·¥å…·"""
        parameters = {
            "data_path": "tests/data/test.csv",
            "method": "t-test"
        }

        result = statistical_analysis(parameters)

        assert "message" in result
        assert "result" in result
        assert "files" in result["result"]
        assert "images" in result["result"]
        assert isinstance(result["result"]["images"][0], Image.Image)

    def test_missing_parameters(self):
        """æµ‹è¯•ç¼ºå¤±å‚æ•°"""
        with pytest.raises(InvalidParameterError):
            statistical_analysis({})

    def test_invalid_data_path(self):
        """æµ‹è¯•æ— æ•ˆæ•°æ®è·¯å¾„"""
        with pytest.raises(FileNotFoundError):
            statistical_analysis({"data_path": "nonexistent.csv"})
```

### 11.5 æ€§èƒ½ä¼˜åŒ–

#### ä½¿ç”¨ç¼“å­˜

```python
from functools import lru_cache
import hashlib
import pickle

def cache_result(cache_file: str):
    """ç»“æœç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜é”®
            key = hashlib.md5(pickle.dumps((args, kwargs))).hexdigest()
            cache_path = Path(cache_file) / f"{key}.pkl"

            # æ£€æŸ¥ç¼“å­˜
            if cache_path.exists():
                with open(cache_path, 'rb') as f:
                    return pickle.load(f)

            # æ‰§è¡Œå‡½æ•°
            result = func(*args, **kwargs)

            # ä¿å­˜ç»“æœ
            cache_path.parent.mkdir(parents=True, exist_ok=True)
            with open(cache_path, 'wb') as f:
                pickle.dump(result, f)

            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@cache_result("cache/tool_results")
def expensive_computation(parameters: dict) -> dict:
    """è€—æ—¶çš„è®¡ç®—"""
    # ... å¤æ‚è®¡ç®— ...
    pass
```

#### æ‰¹é‡å¤„ç†

```python
def batch_process_tool_calls(tools: list, parameters: dict) -> list:
    """æ‰¹é‡è°ƒç”¨å·¥å…·"""

    from concurrent.futures import ThreadPoolExecutor

    def call_tool(tool_name, params):
        tool_func = TOOL_FUNCTIONS.get(tool_name)
        if tool_func:
            return tool_name, tool_func(params)
        return tool_name, None

    results = {}
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = {
            executor.submit(call_tool, tool_name, parameters): tool_name
            for tool_name in tools
        }

        for future in futures:
            tool_name, result = future.result()
            results[tool_name] = result

    return results
```

---

## 12. æ•…éšœæ’æŸ¥

### 12.1 å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### é—®é¢˜ 1ï¼šæ¨¡å—å¯¼å…¥é”™è¯¯

**é”™è¯¯ä¿¡æ¯ï¼š**
```
ModuleNotFoundError: No module named 'gradio'
```

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
source venv/bin/activate

# é‡æ–°å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python -c "import gradio; print(gradio.__version__)"
```

#### é—®é¢˜ 2ï¼šå·¥ä½œæµçŠ¶æ€ä¸¢å¤±

**ç—‡çŠ¶ï¼š** ç³»ç»Ÿé‡å¯åï¼Œä¹‹å‰çš„å·¥ä½œæµæ— æ³•æ¢å¤

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨æŒä¹…åŒ–ç®¡ç†å™¨
from core.state_manager import PersistentWorkflowManager

workflow_manager = PersistentWorkflowManager()

# å¯åŠ¨æ—¶æ¢å¤ä¸­æ–­çš„å·¥ä½œæµ
count = workflow_manager.load_interrupted_workflows()
print(f"æ¢å¤äº† {count} ä¸ªä¸­æ–­çš„å·¥ä½œæµ")
```

#### é—®é¢˜ 3ï¼šå›¾ç‰‡æ— æ³•æ˜¾ç¤º

**ç—‡çŠ¶ï¼š** Gallery ç»„ä»¶æ˜¾ç¤ºç©ºç™½æˆ–é”™è¯¯

**å¯èƒ½åŸå› ï¼š**
1. PIL.Image å¯¹è±¡æ ¼å¼é”™è¯¯
2. å›¾ç‰‡å°ºå¯¸è¿‡å¤§
3. é¢œè‰²æ¨¡å¼ä¸æ”¯æŒ

**è§£å†³æ–¹æ¡ˆï¼š**
```python
def normalize_image(img: Image.Image) -> Image.Image:
    """æ ‡å‡†åŒ–å›¾ç‰‡å¯¹è±¡"""

    # è½¬æ¢é¢œè‰²æ¨¡å¼
    if img.mode not in ['RGB', 'RGBA']:
        img = img.convert('RGB')

    # è°ƒæ•´å¤§å°ï¼ˆå¦‚æœå¤ªå¤§ï¼‰
    max_size = (2000, 2000)
    if img.size[0] > max_size[0] or img.size[1] > max_size[1]:
        img.thumbnail(max_size, Image.Resampling.LANCZOS)

    return img

# åœ¨å·¥å…·å‡½æ•°ä¸­ä½¿ç”¨
def my_tool(parameters: dict) -> dict:
    # ...
    normalized_images = [normalize_image(img) for img in images]

    return {
        "message": "å®Œæˆ",
        "result": {
            "files": files,
            "images": normalized_images
        }
    }
```

#### é—®é¢˜ 4ï¼šå†…å­˜å ç”¨è¿‡é«˜

**ç—‡çŠ¶ï¼š** é•¿æ—¶é—´è¿è¡Œåå†…å­˜å ç”¨æŒç»­å¢é•¿

**è§£å†³æ–¹æ¡ˆï¼š**
```python
import gc

def cleanup_old_workflows(max_age_hours=24):
    """æ¸…ç†æ—§å·¥ä½œæµ"""
    from datetime import datetime, timedelta

    now = datetime.now()
    cutoff = now - timedelta(hours=max_age_hours)

    expired_runs = []
    for run_id, state in workflow_manager.active_workflows.items():
        created = datetime.fromisoformat(state.get('created_at', now.isoformat()))
        if created < cutoff:
            expired_runs.append(run_id)

    for run_id in expired_runs:
        # æ¸…ç†å¯¹è¯å†å²
        if run_id in workflow_manager.conversation_history:
            del workflow_manager.conversation_history[run_id]

        # æ¸…ç†å·¥ä½œæµçŠ¶æ€
        del workflow_manager.active_workflows[run_id]

    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    gc.collect()

    return len(expired_runs)

# å®šæ—¶æ¸…ç†
import schedule
schedule.every(1).hours.do(cleanup_old_workflows)
```

#### é—®é¢˜ 5ï¼šGradio ç•Œé¢æ— å“åº”

**ç—‡çŠ¶ï¼š** æäº¤åé•¿æ—¶é—´æ²¡æœ‰å“åº”

**è§£å†³æ–¹æ¡ˆï¼š**
```python
# ä½¿ç”¨å¼‚æ­¥å¤„ç†
import asyncio

async def async_process_user_message(user_input: str, history: list):
    """å¼‚æ­¥å¤„ç†æ¶ˆæ¯"""

    # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè€—æ—¶æ“ä½œ
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        None,  # ä½¿ç”¨é»˜è®¤æ‰§è¡Œå™¨
        process_user_message,
        user_input,
        history
    )

    return result

# åœ¨ Gradio ä¸­ä½¿ç”¨
demo = gr.Interface(
    fn=async_process_user_message,
    inputs=[gr.Textbox(), gr.Chatbot()],
    outputs=[gr.Chatbot(), gr.Gallery()]
)
```

### 12.2 è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

# å¯ç”¨è°ƒè¯•æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

# åœ¨ä»£ç ä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
logger.debug(f"å¤„ç†ç”¨æˆ·è¾“å…¥: {user_input}")
logger.debug(f"å·¥ä½œæµçŠ¶æ€: {workflow_info}")
logger.debug(f"å·¥å…·è¾“å‡º: {tool_output}")
```

#### ä½¿ç”¨æ–­ç‚¹è°ƒè¯•

```python
# åœ¨ä»£ç ä¸­æ’å…¥æ–­ç‚¹
def start_workflow(user_input: str) -> str:
    run_id = create_workflow(user_input)

    # åœ¨è¿™é‡Œæš‚åœæ‰§è¡Œï¼Œè¿›å…¥è°ƒè¯•æ¨¡å¼
    breakpoint()

    # æ£€æŸ¥å˜é‡
    print(f"run_id = {run_id}")
    print(f"locals() = {locals()}")

    return run_id
```

#### æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

def profile_workflow():
    """æ€§èƒ½åˆ†æ"""

    profiler = cProfile.Profile()
    profiler.enable()

    # æ‰§è¡Œå·¥ä½œæµ
    run_id = start_workflow("åˆ†æé”€å”®æ•°æ®")
    info = get_workflow_info(run_id)

    profiler.disable()

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    stats = pstats.Stats(profiler)
    stats.sort_stats('cumulative')
    stats.print_stats(10)  # æ˜¾ç¤ºå‰10ä¸ªæœ€è€—æ—¶çš„å‡½æ•°

# è¿è¡Œåˆ†æ
profile_workflow()
```

### 12.3 å¥åº·æ£€æŸ¥

```python
def health_check() -> dict:
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""

    status = {
        "status": "healthy",
        "checks": {}
    }

    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    import shutil
    disk_usage = shutil.disk_usage("/")
    free_percent = (disk_usage.free / disk_usage.total) * 100
    status["checks"]["disk"] = {
        "status": "ok" if free_percent > 10 else "warning",
        "free_percent": free_percent
    }

    # æ£€æŸ¥å†…å­˜ä½¿ç”¨
    import psutil
    memory = psutil.virtual_memory()
    status["checks"]["memory"] = {
        "status": "ok" if memory.percent < 80 else "warning",
        "used_percent": memory.percent
    }

    # æ£€æŸ¥æ´»è·ƒå·¥ä½œæµæ•°
    active_count = len(workflow_manager.active_workflows)
    status["checks"]["workflows"] = {
        "status": "ok" if active_count < 100 else "warning",
        "active_count": active_count
    }

    # æ€»ä½“çŠ¶æ€
    if any(check["status"] == "warning" for check in status["checks"].values()):
        status["status"] = "warning"

    return status

# åˆ›å»ºå¥åº·æ£€æŸ¥ç«¯ç‚¹
def create_health_endpoint():
    """åˆ›å»ºå¥åº·æ£€æŸ¥ç•Œé¢"""
    return gr.Interface(
        fn=lambda: gr.JSON(value=health_check()),
        inputs=[],
        outputs=[gr.JSON(label="ç³»ç»ŸçŠ¶æ€")],
        title="ç³»ç»Ÿå¥åº·æ£€æŸ¥"
    )
```

---

## ğŸ“ æ€»ç»“

æœ¬æ•™ç¨‹æ¶µç›–äº†å·¥ä½œæµå¯¹è¯æœºå™¨äººçš„å®Œæ•´å¼€å‘æµç¨‹ï¼š

âœ… **åŸºç¡€æ¦‚å¿µ**ï¼šå·¥ä½œæµã€çŠ¶æ€æœºã€RunIDã€å¯¹è¯å†å²ç­‰
âœ… **ç³»ç»Ÿæ¶æ„**ï¼šåˆ†å±‚è®¾è®¡ã€æ•°æ®æµã€æ¨¡å—å…³ç³»
âœ… **æ ¸å¿ƒç»„ä»¶**ï¼šçŠ¶æ€ç®¡ç†å™¨ã€å·¥ä½œæµå‡½æ•°ã€å·¥å…·å‡½æ•°
âœ… **å®æˆ˜æ•™ç¨‹**ï¼šä»ç®€å•å·¥å…·åˆ°å¤æ‚å·¥ä½œæµçš„å®ç°
âœ… **é«˜çº§åŠŸèƒ½**ï¼šå¹¶å‘å¤„ç†ã€è¶…æ—¶ç®¡ç†ã€æµå¼è¾“å‡º
âœ… **éƒ¨ç½²æŒ‡å—**ï¼šæœ¬åœ°ã€Dockerã€äº‘æœåŠ¡éƒ¨ç½²
âœ… **æœ€ä½³å®è·µ**ï¼šä»£ç ç»„ç»‡ã€é”™è¯¯å¤„ç†ã€æµ‹è¯•ã€ä¼˜åŒ–
âœ… **æ•…éšœæ’æŸ¥**ï¼šå¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### ä¸‹ä¸€æ­¥

1. ğŸš€ å®ç°ä½ çš„å®é™…å·¥ä½œæµå‡½æ•°
2. ğŸ”§ æ·»åŠ è‡ªå®šä¹‰åˆ†æå·¥å…·
3. ğŸ“Š é›†æˆçœŸå®çš„æ•°æ®åˆ†æåº“
4. ğŸ¨ å®šåˆ¶ç•Œé¢æ ·å¼å’Œäº¤äº’
5. ğŸ“ˆ ç›‘æ§å’Œä¼˜åŒ–æ€§èƒ½

ç¥ä½ å¼€å‘é¡ºåˆ©ï¼ğŸ‰
