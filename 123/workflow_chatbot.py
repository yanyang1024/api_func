#!/usr/bin/env python3
"""
å·¥ä½œæµå¯¹è¯æœºå™¨äºº - Gradioç•Œé¢
æ”¯æŒä¸å·¥ä½œæµæ™ºèƒ½ä½“çš„å¤šè½®å¯¹è¯ï¼Œå¤„ç†ä¸­æ–­å’Œæ¢å¤çŠ¶æ€
"""

import gradio as gr
from typing import Dict, List, Tuple, Optional
import os
import json
from datetime import datetime
from PIL import Image
import io

# ==================== æ¨¡æ‹Ÿå‡½æ•°åŒºåŸŸ ====================
# æ³¨æ„ï¼šè¿™äº›æ˜¯æ¨¡æ‹Ÿå‡½æ•°ï¼Œåç»­è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å®ç°

def start_workflow(user_input: str) -> str:
    """
    å¯åŠ¨å·¥ä½œæµ
    å‚æ•°: user_input - ç”¨æˆ·è‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²
    è¿”å›: run_id - å·¥ä½œæµè¿è¡ŒID
    """
    # æ¨¡æ‹Ÿç”Ÿæˆä¸€ä¸ªrunID
    run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"[Mock] å¯åŠ¨å·¥ä½œæµ - ç”¨æˆ·è¾“å…¥: {user_input}, ç”Ÿæˆ runID: {run_id}")
    return run_id

def get_workflow_info(run_id: str) -> Dict:
    """
    é€šè¿‡runIDè®¿é—®å·¥ä½œæµä¿¡æ¯
    å‚æ•°: run_id - å·¥ä½œæµè¿è¡ŒID
    è¿”å›: å·¥ä½œæµä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« status (interrupted/completed) å’Œç›¸å…³æ•°æ®
    """
    # æ¨¡æ‹Ÿè¿”å›ä¸åŒçš„çŠ¶æ€
    print(f"[Mock] è·å–å·¥ä½œæµä¿¡æ¯ - runID: {run_id}")

    # è¿™é‡Œæ¨¡æ‹Ÿä¸åŒçš„æƒ…å†µï¼Œå®é™…ä½¿ç”¨æ—¶æ ¹æ®ä½ çš„é€»è¾‘è°ƒæ•´
    # ç¬¬ä¸€æ¬¡è°ƒç”¨è¿”å›ä¸­æ–­çŠ¶æ€ï¼Œç¬¬äºŒæ¬¡è¿”å›å®ŒæˆçŠ¶æ€
    mock_response = {
        "run_id": run_id,
        "status": "completed",  # æˆ– "interrupted"
        "message": "å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
        "data": {}
    }

    return mock_response

def resume_workflow(user_input: str, run_id: str) -> str:
    """
    é‡å¯ä¸­æ–­çš„å·¥ä½œæµ
    å‚æ•°:
        user_input - ç”¨æˆ·è‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²
        run_id - å·¥ä½œæµè¿è¡ŒID
    è¿”å›: æ›´æ–°åçš„ run_id (å¯èƒ½æ˜¯åŒä¸€ä¸ªæˆ–æ–°çš„)
    """
    print(f"[Mock] é‡å¯å·¥ä½œæµ - ç”¨æˆ·è¾“å…¥: {user_input}, runID: {run_id}")
    return run_id

# æ¨¡æ‹Ÿçš„åˆ†æå·¥å…·å‡½æ•°
def tool_inline_compare(parameters: dict) -> Dict:
    """å†…è”å¯¹æ¯”åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ inline_compare - å‚æ•°: {parameters}")

    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å‡ºæ–‡ä»¶
    os.makedirs("outputs", exist_ok=True)
    ppt_path = "outputs/compare_result.pptx"
    csv_path = "outputs/test_results.csv"
    data_path = "outputs/raw_data.csv"

    # åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºæ¨¡æ‹Ÿ
    for path in [ppt_path, csv_path, data_path]:
        with open(path, 'w') as f:
            f.write(f"Mock output created at {datetime.now()}")

    # åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡
    img1 = Image.new('RGBA', (2000, 1000), color=(255, 100, 100, 255))
    img2 = Image.new('RGBA', (1500, 800), color=(100, 255, 100, 255))

    return {
        "message": "Inline compare Processing completed!",
        "result": {
            "files": [ppt_path, csv_path, data_path],
            "images": [img1, img2]
        }
    }

def tool_statistical_analysis(parameters: dict) -> Dict:
    """ç»Ÿè®¡åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ statistical_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    report_path = "outputs/statistical_report.pdf"
    chart_path = "outputs/statistical_chart.csv"

    for path in [report_path, chart_path]:
        with open(path, 'w') as f:
            f.write(f"Mock statistical output at {datetime.now()}")

    img1 = Image.new('RGBA', (1200, 800), color=(100, 100, 255, 255))

    return {
        "message": "Statistical analysis completed!",
        "result": {
            "files": [report_path, chart_path],
            "images": [img1]
        }
    }

def tool_trend_analysis(parameters: dict) -> Dict:
    """è¶‹åŠ¿åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ trend_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    trend_path = "outputs/trend_report.xlsx"
    forecast_path = "outputs/forecast_data.csv"

    for path in [trend_path, forecast_path]:
        with open(path, 'w') as f:
            f.write(f"Mock trend analysis at {datetime.now()}")

    img1 = Image.new('RGBA', (1800, 900), color=(255, 255, 100, 255))
    img2 = Image.new('RGBA', (1600, 800), color=(255, 150, 50, 255))

    return {
        "message": "Trend analysis completed!",
        "result": {
            "files": [trend_path, forecast_path],
            "images": [img1, img2]
        }
    }

def tool_correlation_analysis(parameters: dict) -> Dict:
    """ç›¸å…³æ€§åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ correlation_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    correlation_path = "outputs/correlation_matrix.csv"
    heatmap_path = "outputs/heatmap_data.csv"

    for path in [correlation_path, heatmap_path]:
        with open(path, 'w') as f:
            f.write(f"Mock correlation analysis at {datetime.now()}")

    img1 = Image.new('RGBA', (1400, 1400), color=(150, 50, 255, 255))

    return {
        "message": "Correlation analysis completed!",
        "result": {
            "files": [correlation_path, heatmap_path],
            "images": [img1]
        }
    }

# å·¥å…·å‡½æ•°æ˜ å°„
TOOL_FUNCTIONS = {
    "inline_compare": tool_inline_compare,
    "statistical_analysis": tool_statistical_analysis,
    "trend_analysis": tool_trend_analysis,
    "correlation_analysis": tool_correlation_analysis
}

# ==================== å·¥ä½œæµçŠ¶æ€ç®¡ç† ====================

class WorkflowStateManager:
    """ç®¡ç†å·¥ä½œæµçŠ¶æ€å’Œå¯¹è¯å†å²"""

    def __init__(self):
        self.active_workflows: Dict[str, Dict] = {}
        self.conversation_history: Dict[str, List[Dict]] = {}

    def save_workflow_state(self, run_id: str, state: dict):
        """ä¿å­˜å·¥ä½œæµçŠ¶æ€"""
        self.active_workflows[run_id] = state

    def get_workflow_state(self, run_id: str) -> Optional[Dict]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        return self.active_workflows.get(run_id)

    def add_to_history(self, run_id: str, role: str, content: str, metadata: dict = None):
        """æ·»åŠ å¯¹è¯å†å²"""
        if run_id not in self.conversation_history:
            self.conversation_history[run_id] = []

        self.conversation_history[run_id].append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        })

    def get_history(self, run_id: str) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.get(run_id, [])

# å…¨å±€çŠ¶æ€ç®¡ç†å™¨
workflow_manager = WorkflowStateManager()

# ==================== ç»“æœå¤„ç†å‡½æ•° ====================

def process_tool_results(tool_output: Dict, run_id: str) -> Tuple[str, List, List]:
    """
    å¤„ç†å·¥å…·è¾“å‡ºç»“æœï¼Œæ ¼å¼åŒ–ä¸ºå‰ç«¯å±•ç¤º
    è¿”å›: (summary_text, display_images, file_paths)
    """
    if "result" not in tool_output:
        return tool_output.get("message", "å¤„ç†å®Œæˆ"), [], []

    result = tool_output["result"]
    files = result.get("files", [])
    images = result.get("images", [])

    display_images = []
    file_paths = []
    summary_parts = []

    # å¤„ç†æ¶ˆæ¯
    summary_parts.append(f"âœ… {tool_output.get('message', 'å¤„ç†å®Œæˆ')}")

    # å¤„ç†å›¾ç‰‡
    if images:
        summary_parts.append(f"\nğŸ“Š ç”Ÿæˆäº† {len(images)} ä¸ªå¯è§†åŒ–å›¾è¡¨ï¼š")
        for idx, img in enumerate(images, 1):
            if isinstance(img, Image.Image):
                display_images.append(img)
                summary_parts.append(f"  - å›¾è¡¨ {idx}: {img.size[0]}x{img.size[1]} åƒç´ ")
            else:
                summary_parts.append(f"  - å›¾è¡¨ {idx}: [éå›¾ç‰‡å¯¹è±¡]")

    # å¤„ç†æ–‡ä»¶
    if files:
        summary_parts.append(f"\nğŸ“ ç”Ÿæˆäº† {len(files)} ä¸ªæ•°æ®æ–‡ä»¶ï¼š")
        for file_path in files:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                file_name = os.path.basename(file_path)
                file_paths.append(file_path)
                summary_parts.append(f"  - {file_name} ({file_size} bytes)")
            else:
                summary_parts.append(f"  - {os.path.basename(file_path)} [æ–‡ä»¶ä¸å­˜åœ¨]")

    # è·å–å†å²ä¿¡æ¯
    history = workflow_manager.get_history(run_id)
    if history:
        summary_parts.append(f"\nğŸ’¬ å¯¹è¯è½®æ¬¡: {len(history)}")

    summary = "\n".join(summary_parts)
    return summary, display_images, file_paths

def format_interrupted_response(workflow_info: Dict, run_id: str) -> str:
    """æ ¼å¼åŒ–ä¸­æ–­çŠ¶æ€å“åº”"""
    message = workflow_info.get("message", "å·¥ä½œæµéœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½ç»§ç»­")

    response = f"â¸ï¸ **å·¥ä½œæµå·²æš‚åœ**\n\n{message}\n\n"
    response += "è¯·æä¾›éœ€è¦çš„ä¿¡æ¯ä»¥ç»§ç»­å·¥ä½œæµã€‚"

    return response

def format_completed_response(workflow_info: Dict, run_id: str) -> Tuple[str, List, List]:
    """æ ¼å¼åŒ–å®ŒæˆçŠ¶æ€å“åº”"""
    # è·å–è§£æçš„å‚æ•°
    data = workflow_info.get("data", {})
    extracted_params = data.get("parameters", {})

    response_parts = []
    response_parts.append("âœ… **å·¥ä½œæµæ‰§è¡Œå®Œæˆ**\n")

    # æ˜¾ç¤ºæå–çš„å‚æ•°
    if extracted_params:
        response_parts.append("\nğŸ“‹ **è§£æçš„å‚æ•°ï¼š**\n")
        for key, value in extracted_params.items():
            response_parts.append(f"  - {key}: {value}")

    # è°ƒç”¨ç›¸åº”çš„å·¥å…·å‡½æ•°
    all_display_images = []
    all_file_paths = []
    tool_results = []

    # å‡è®¾ workflow_info ä¸­åŒ…å«äº†éœ€è¦è°ƒç”¨çš„å·¥å…·ä¿¡æ¯
    tools_to_run = data.get("tools", [])

    if not tools_to_run:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå·¥å…·ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æˆ–å‚æ•°æ¨æ–­
        # è¿™é‡Œæ¨¡æ‹Ÿæ ¹æ®å‚æ•°é€‰æ‹©å·¥å…·
        if "compare" in str(extracted_params).lower():
            tools_to_run = ["inline_compare"]
        elif "statistical" in str(extracted_params).lower():
            tools_to_run = ["statistical_analysis"]
        else:
            # é»˜è®¤è¿è¡Œ inline_compare
            tools_to_run = ["inline_compare"]

    for tool_name in tools_to_run:
        if tool_name in TOOL_FUNCTIONS:
            try:
                print(f"\n[INFO] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_output = TOOL_FUNCTIONS[tool_name](extracted_params)
                tool_results.append(tool_output)

                # å¤„ç†æ¯ä¸ªå·¥å…·çš„ç»“æœ
                summary, display_images, file_paths = process_tool_results(tool_output, run_id)
                response_parts.append(f"\n{summary}")
                all_display_images.extend(display_images)
                all_file_paths.extend(file_paths)

            except Exception as e:
                error_msg = f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
                response_parts.append(f"\n{error_msg}")
                print(f"[ERROR] {error_msg}")

    final_response = "\n".join(response_parts)
    return final_response, all_display_images, all_file_paths

# ==================== å¯¹è¯å¤„ç†é€»è¾‘ ====================

def process_user_message(user_input: str, history: List) -> Tuple[List, List, List]:
    """
    å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»è¦é€»è¾‘
    è¿”å›: (updated_history, display_images, file_paths)
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ
    active_run_id = None

    # æŸ¥æ‰¾æœ€è¿‘çš„ä¸­æ–­å·¥ä½œæµ
    for run_id, state in workflow_manager.active_workflows.items():
        if state.get("status") == "interrupted":
            active_run_id = run_id
            break

    display_images = []
    file_paths = []

    if active_run_id:
        # æœ‰ä¸­æ–­çš„å·¥ä½œæµï¼Œéœ€è¦æ¢å¤
        print(f"\n[INFO] æ£€æµ‹åˆ°ä¸­æ–­çš„å·¥ä½œæµ: {active_run_id}")

        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²
        workflow_manager.add_to_history(active_run_id, "user", user_input)

        # æ¢å¤å·¥ä½œæµ
        resume_workflow(user_input, active_run_id)

        # è·å–æ›´æ–°åçš„å·¥ä½œæµä¿¡æ¯
        workflow_info = get_workflow_info(active_run_id)

        # æ›´æ–°çŠ¶æ€
        workflow_manager.save_workflow_state(active_run_id, workflow_info)

        # æ ¹æ®çŠ¶æ€ç”Ÿæˆå“åº”
        if workflow_info.get("status") == "interrupted":
            # ä»ç„¶ä¸­æ–­
            response = format_interrupted_response(workflow_info, active_run_id)
            workflow_manager.add_to_history(active_run_id, "assistant", response)
            history.append([user_input, response])

        elif workflow_info.get("status") == "completed":
            # å®Œæˆ
            response, display_images, file_paths = format_completed_response(workflow_info, active_run_id)
            workflow_manager.add_to_history(active_run_id, "assistant", response)
            history.append([user_input, response])

            # æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆ
            workflow_manager.save_workflow_state(active_run_id, {
                **workflow_info,
                "status": "completed"
            })

        else:
            # æœªçŸ¥çŠ¶æ€
            response = f"âš ï¸ æœªçŸ¥çš„å·¥ä½œæµçŠ¶æ€: {workflow_info.get('status')}"
            history.append([user_input, response])

    else:
        # æ²¡æœ‰æ´»è·ƒå·¥ä½œæµï¼Œå¯åŠ¨æ–°çš„
        print(f"\n[INFO] å¯åŠ¨æ–°çš„å·¥ä½œæµ")

        # å¯åŠ¨å·¥ä½œæµ
        run_id = start_workflow(user_input)

        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        workflow_manager.add_to_history(run_id, "user", user_input)

        # è·å–å·¥ä½œæµä¿¡æ¯
        workflow_info = get_workflow_info(run_id)

        # ä¿å­˜çŠ¶æ€
        workflow_manager.save_workflow_state(run_id, workflow_info)

        # æ ¹æ®çŠ¶æ€ç”Ÿæˆå“åº”
        if workflow_info.get("status") == "interrupted":
            response = format_interrupted_response(workflow_info, run_id)
            workflow_manager.add_to_history(run_id, "assistant", response)
            history.append([user_input, response])

        elif workflow_info.get("status") == "completed":
            response, display_images, file_paths = format_completed_response(workflow_info, run_id)
            workflow_manager.add_to_history(run_id, "assistant", response)
            history.append([user_input, response])

        else:
            response = f"âš ï¸ æœªçŸ¥çš„å·¥ä½œæµçŠ¶æ€: {workflow_info.get('status')}"
            history.append([user_input, response])

    return history, display_images, file_paths

def create_gradio_interface():
    """åˆ›å»º Gradio ç•Œé¢"""

    custom_css = """
    .chat-container {
        height: 600px;
    }
    .message {
        padding: 10px;
        margin: 5px 0;
        border-radius: 8px;
    }
    """

    with gr.Blocks(css=custom_css, title="å·¥ä½œæµå¯¹è¯æœºå™¨äºº") as app:

        gr.Markdown("# ğŸ¤– å·¥ä½œæµå¯¹è¯æœºå™¨äºº")
        gr.Markdown("æ”¯æŒä¸å·¥ä½œæµæ™ºèƒ½ä½“çš„å¤šè½®å¯¹è¯ï¼Œè‡ªåŠ¨å¤„ç†ä¸­æ–­å’Œæ¢å¤çŠ¶æ€")

        with gr.Row():
            with gr.Column(scale=2):
                chatbot = gr.Chatbot(
                    label="å¯¹è¯å†å²",
                    height=500,
                    bubble_full_width=False,
                    avatar_images=(None, "ğŸ¤–")
                )

                with gr.Row():
                    msg_input = gr.Textbox(
                        label="è¾“å…¥æ¶ˆæ¯",
                        placeholder="è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚...",
                        scale=4,
                        lines=2
                    )
                    submit_btn = gr.Button("å‘é€", variant="primary", scale=1)
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary", scale=1)

            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“Š ç»“æœå±•ç¤º")
                results_gallery = gr.Gallery(
                    label="ç”Ÿæˆçš„å›¾è¡¨",
                    show_label=True,
                    elem_id="results_gallery",
                    columns=1,
                    rows=5,
                    height="auto",
                    object_fit="contain"
                )

                gr.Markdown("### ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶")
                files_output = gr.File(
                    label="ä¸‹è½½æ–‡ä»¶",
                    file_count="multiple",
                    interactive=False
                )

        # çŠ¶æ€ä¿¡æ¯
        with gr.Accordion("ğŸ”§ çŠ¶æ€ä¿¡æ¯", open=False):
            status_info = gr.Textbox(
                label="å½“å‰çŠ¶æ€",
                value="å‡†å¤‡å°±ç»ª",
                interactive=False
            )
            active_workflows_info = gr.JSON(
                label="æ´»è·ƒçš„å·¥ä½œæµ",
                value={}
            )

        # ç¤ºä¾‹é—®é¢˜
        gr.Markdown("### ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
        examples = gr.Examples(
            examples=[
                ["å¸®æˆ‘å¯¹æ¯”åˆ†æä¸€ä¸‹æ•°æ®é›†Aå’Œæ•°æ®é›†Bçš„å·®å¼‚"],
                ["å¯¹é”€å”®æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ"],
                ["åˆ†æè¿‡å»ä¸€å¹´çš„æ•°æ®è¶‹åŠ¿"],
                ["è®¡ç®—å„ä¸ªå˜é‡ä¹‹é—´çš„ç›¸å…³æ€§"]
            ],
            inputs=msg_input,
            label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿå¼€å§‹"
        )

        def handle_submit(user_input, history):
            """å¤„ç†æäº¤"""
            if not user_input.strip():
                return history, [], "è¯·è¾“å…¥æ¶ˆæ¯", {}

            updated_history, display_images, file_paths = process_user_message(user_input, history)

            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            active_count = sum(
                1 for s in workflow_manager.active_workflows.values()
                if s.get("status") == "interrupted"
            )

            status_msg = f"æ´»è·ƒå·¥ä½œæµæ•°: {active_count} | æ€»å¯¹è¯æ•°: {len(workflow_manager.conversation_history)}"

            # display_images å·²ç»æ˜¯ PIL Image å¯¹è±¡åˆ—è¡¨ï¼Œå¯ä»¥ç›´æ¥ç”¨äºç”»å»Š
            gallery_images = display_images

            # file_paths å·²ç»æ˜¯æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_files = file_paths

            print(f"\n[DEBUG] è¿”å› {len(gallery_images)} ä¸ªå›¾ç‰‡")
            print(f"[DEBUG] è¿”å› {len(output_files)} ä¸ªæ–‡ä»¶: {output_files}")

            return (
                updated_history,
                gallery_images,
                output_files,
                status_msg,
                workflow_manager.active_workflows
            )

        def handle_clear():
            """æ¸…ç©ºå¯¹è¯"""
            workflow_manager.active_workflows.clear()
            workflow_manager.conversation_history.clear()
            return [], [], "å¯¹è¯å·²æ¸…ç©º", {}

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            handle_submit,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        ).then(
            lambda: "",
            outputs=[msg_input]
        )

        msg_input.submit(
            handle_submit,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        ).then(
            lambda: "",
            outputs=[msg_input]
        )

        clear_btn.click(
            handle_clear,
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        )

    return app

# ==================== ä¸»ç¨‹åºå…¥å£ ====================

if __name__ == "__main__":
    print("=" * 60)
    print("å·¥ä½œæµå¯¹è¯æœºå™¨äºº - Gradioç•Œé¢")
    print("=" * 60)
    print("\n[INFO] æ­£åœ¨å¯åŠ¨æœåŠ¡å™¨...")
    print("[INFO] æ¨¡æ‹Ÿå‡½æ•°å·²åŠ è½½ï¼Œåç»­è¯·æ›¿æ¢ä¸ºå®é™…å®ç°\n")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("outputs", exist_ok=True)

    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    app = create_gradio_interface()

    # å¯åŠ¨æœåŠ¡å™¨
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )
