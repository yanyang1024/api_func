#!/usr/bin/env python3
"""
å·¥ä½œæµå¯¹è¯æœºå™¨äºº - Gradioç•Œé¢
æ”¯æŒä¸å·¥ä½œæµæ™ºèƒ½ä½“çš„å¤šè½®å¯¹è¯ï¼Œå¤„ç†ä¸­æ–­å’Œæ¢å¤çŠ¶æ€
"""

import gradio as gr
from typing import Dict, List, Tuple, Optional
import os
import json
from datetime import datetime
from PIL import Image
import io
import time
import hashlib

# ==================== æ¨¡æ‹Ÿå‡½æ•°åŒºåŸŸ ====================
# æ³¨æ„ï¼šè¿™äº›æ˜¯æ¨¡æ‹Ÿå‡½æ•°ï¼Œåç»­è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å®ç°

def start_workflow(user_input: str) -> str:
    """
    å¯åŠ¨å·¥ä½œæµ
    å‚æ•°: user_input - ç”¨æˆ·è‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²
    è¿”å›: run_id - å·¥ä½œæµè¿è¡ŒID
    """
    # æ¨¡æ‹Ÿç”Ÿæˆä¸€ä¸ªrunID
    run_id = f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    print(f"[Mock] å¯åŠ¨å·¥ä½œæµ - ç”¨æˆ·è¾“å…¥: {user_input}, ç”Ÿæˆ runID: {run_id}")
    return run_id

def get_workflow_info(run_id: str) -> Dict:
    """
    é€šè¿‡runIDè®¿é—®å·¥ä½œæµä¿¡æ¯
    å‚æ•°: run_id - å·¥ä½œæµè¿è¡ŒID
    è¿”å›: å·¥ä½œæµä¿¡æ¯å­—å…¸ï¼ŒåŒ…å« status (interrupted/completed) å’Œç›¸å…³æ•°æ®
    """
    # æ¨¡æ‹Ÿè¿”å›ä¸åŒçš„çŠ¶æ€
    print(f"[Mock] è·å–å·¥ä½œæµä¿¡æ¯ - runID: {run_id}")

    # è¿™é‡Œæ¨¡æ‹Ÿä¸åŒçš„æƒ…å†µï¼Œå®é™…ä½¿ç”¨æ—¶æ ¹æ®ä½ çš„é€»è¾‘è°ƒæ•´
    # ç¬¬ä¸€æ¬¡è°ƒç”¨è¿”å›ä¸­æ–­çŠ¶æ€ï¼Œç¬¬äºŒæ¬¡è¿”å›å®ŒæˆçŠ¶æ€
    mock_response = {
        "run_id": run_id,
        "status": "completed",  # æˆ– "interrupted"
        "message": "å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ",
        "data": {}
    }

    return mock_response

def resume_workflow(user_input: str, run_id: str) -> str:
    """
    é‡å¯ä¸­æ–­çš„å·¥ä½œæµ
    å‚æ•°:
        user_input - ç”¨æˆ·è‡ªç„¶è¯­è¨€å­—ç¬¦ä¸²
        run_id - å·¥ä½œæµè¿è¡ŒID
    è¿”å›: æ›´æ–°åçš„ run_id (å¯èƒ½æ˜¯åŒä¸€ä¸ªæˆ–æ–°çš„)
    """
    print(f"[Mock] é‡å¯å·¥ä½œæµ - ç”¨æˆ·è¾“å…¥: {user_input}, runID: {run_id}")
    return run_id

# æ¨¡æ‹Ÿçš„åˆ†æå·¥å…·å‡½æ•°
def tool_inline_compare(parameters: dict) -> Dict:
    """å†…è”å¯¹æ¯”åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ inline_compare - å‚æ•°: {parameters}")

    # åˆ›å»ºæ¨¡æ‹Ÿè¾“å‡ºæ–‡ä»¶
    os.makedirs("outputs", exist_ok=True)
    ppt_path = "outputs/compare_result.pptx"
    csv_path = "outputs/test_results.csv"
    data_path = "outputs/raw_data.csv"

    # åˆ›å»ºç©ºæ–‡ä»¶ä½œä¸ºæ¨¡æ‹Ÿ
    for path in [ppt_path, csv_path, data_path]:
        with open(path, 'w') as f:
            f.write(f"Mock output created at {datetime.now()}")

    # åˆ›å»ºæ¨¡æ‹Ÿå›¾ç‰‡
    img1 = Image.new('RGBA', (2000, 1000), color=(255, 100, 100, 255))
    img2 = Image.new('RGBA', (1500, 800), color=(100, 255, 100, 255))

    return {
        "message": "Inline compare Processing completed!",
        "result": {
            "files": [ppt_path, csv_path, data_path],
            "images": [img1, img2]
        }
    }

def tool_statistical_analysis(parameters: dict) -> Dict:
    """ç»Ÿè®¡åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ statistical_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    report_path = "outputs/statistical_report.pdf"
    chart_path = "outputs/statistical_chart.csv"

    for path in [report_path, chart_path]:
        with open(path, 'w') as f:
            f.write(f"Mock statistical output at {datetime.now()}")

    img1 = Image.new('RGBA', (1200, 800), color=(100, 100, 255, 255))

    return {
        "message": "Statistical analysis completed!",
        "result": {
            "files": [report_path, chart_path],
            "images": [img1]
        }
    }

def tool_trend_analysis(parameters: dict) -> Dict:
    """è¶‹åŠ¿åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ trend_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    trend_path = "outputs/trend_report.xlsx"
    forecast_path = "outputs/forecast_data.csv"

    for path in [trend_path, forecast_path]:
        with open(path, 'w') as f:
            f.write(f"Mock trend analysis at {datetime.now()}")

    img1 = Image.new('RGBA', (1800, 900), color=(255, 255, 100, 255))
    img2 = Image.new('RGBA', (1600, 800), color=(255, 150, 50, 255))

    return {
        "message": "Trend analysis completed!",
        "result": {
            "files": [trend_path, forecast_path],
            "images": [img1, img2]
        }
    }

def tool_correlation_analysis(parameters: dict) -> Dict:
    """ç›¸å…³æ€§åˆ†æå·¥å…·"""
    print(f"[Mock] æ‰§è¡Œ correlation_analysis - å‚æ•°: {parameters}")

    os.makedirs("outputs", exist_ok=True)
    correlation_path = "outputs/correlation_matrix.csv"
    heatmap_path = "outputs/heatmap_data.csv"

    for path in [correlation_path, heatmap_path]:
        with open(path, 'w') as f:
            f.write(f"Mock correlation analysis at {datetime.now()}")

    img1 = Image.new('RGBA', (1400, 1400), color=(150, 50, 255, 255))

    return {
        "message": "Correlation analysis completed!",
        "result": {
            "files": [correlation_path, heatmap_path],
            "images": [img1]
        }
    }

# å·¥å…·å‡½æ•°æ˜ å°„
TOOL_FUNCTIONS = {
    "inline_compare": tool_inline_compare,
    "statistical_analysis": tool_statistical_analysis,
    "trend_analysis": tool_trend_analysis,
    "correlation_analysis": tool_correlation_analysis
}

# ==================== å·¥ä½œæµçŠ¶æ€ç®¡ç† ====================

class WorkflowStateManager:
    """ç®¡ç†å·¥ä½œæµçŠ¶æ€å’Œå¯¹è¯å†å²"""

    def __init__(self):
        self.active_workflows: Dict[str, Dict] = {}
        self.conversation_history: Dict[str, List[Dict]] = {}
        # ç¼“å­˜ä¸Šä¸€æ¬¡çš„å·¥ä½œæµä¿¡æ¯ï¼Œç”¨äºçŠ¶æ€å»é‡
        self.last_workflow_info: Dict[str, Dict] = {}
        # è®°å½•æœ€åä¸€æ¬¡ä¸ç”¨æˆ·äº¤äº’çš„æ—¶é—´
        self.last_interaction_time: Dict[str, float] = {}

    def save_workflow_state(self, run_id: str, state: dict):
        """ä¿å­˜å·¥ä½œæµçŠ¶æ€"""
        self.active_workflows[run_id] = state

    def get_workflow_state(self, run_id: str) -> Optional[Dict]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        return self.active_workflows.get(run_id)

    def save_last_workflow_info(self, run_id: str, info: dict):
        """ä¿å­˜ä¸Šä¸€æ¬¡çš„å·¥ä½œæµä¿¡æ¯ç”¨äºæ¯”è¾ƒ"""
        self.last_workflow_info[run_id] = info

    def get_last_workflow_info(self, run_id: str) -> Optional[Dict]:
        """è·å–ä¸Šä¸€æ¬¡çš„å·¥ä½œæµä¿¡æ¯"""
        return self.last_workflow_info.get(run_id)

    def update_interaction_time(self, run_id: str):
        """æ›´æ–°æœ€åä¸€æ¬¡äº¤äº’æ—¶é—´"""
        self.last_interaction_time[run_id] = time.time()

    def get_last_interaction_time(self, run_id: str) -> float:
        """è·å–æœ€åä¸€æ¬¡äº¤äº’æ—¶é—´"""
        return self.last_interaction_time.get(run_id, 0)

    def add_to_history(self, run_id: str, role: str, content: str, metadata: dict = None):
        """æ·»åŠ å¯¹è¯å†å²"""
        if run_id not in self.conversation_history:
            self.conversation_history[run_id] = []

        self.conversation_history[run_id].append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        })

    def get_history(self, run_id: str) -> List[Dict]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.get(run_id, [])

# å…¨å±€çŠ¶æ€ç®¡ç†å™¨
workflow_manager = WorkflowStateManager()

# ==================== è¾…åŠ©å‡½æ•° ====================

def compare_workflow_info(info1: Dict, info2: Dict) -> bool:
    """
    æ¯”è¾ƒä¸¤ä¸ªå·¥ä½œæµä¿¡æ¯æ˜¯å¦ç›¸åŒ
    è¿”å›: True è¡¨ç¤ºç›¸åŒï¼ŒFalse è¡¨ç¤ºä¸åŒ
    """
    # å°†å­—å…¸è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²åè®¡ç®—å“ˆå¸Œå€¼è¿›è¡Œæ¯”è¾ƒ
    # æ’é™¤ timestamp ç­‰å¯èƒ½å˜åŒ–çš„å­—æ®µ
    def normalize_info(info: Dict) -> str:
        filtered = {
            k: v for k, v in info.items()
            if k not in ['timestamp', 'query_time']
        }
        return json.dumps(filtered, sort_keys=True)

    return normalize_info(info1) == normalize_info(info2)

def poll_workflow_info(run_id: str, max_retries: int = 15, initial_interval: float = 0.5) -> Tuple[Dict, int]:
    """
    è½®è¯¢å·¥ä½œæµä¿¡æ¯ç›´åˆ°æœ‰æ›´æ–°æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
    ä½¿ç”¨æ™ºèƒ½é€€é¿ç­–ç•¥ï¼šåˆå§‹é—´éš”çŸ­ï¼Œé€æ¸å¢åŠ é—´éš”
    å‚æ•°:
        run_id: å·¥ä½œæµID
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤15æ¬¡ï¼‰
        initial_interval: åˆå§‹é‡è¯•é—´éš”ç§’æ•°ï¼ˆé»˜è®¤0.5ç§’ï¼‰
    è¿”å›: (workflow_info, attempts) - å·¥ä½œæµä¿¡æ¯å’Œå®é™…å°è¯•æ¬¡æ•°
    """
    print(f"[INFO] å¼€å§‹è½®è¯¢å·¥ä½œæµ {run_id} çš„ä¿¡æ¯æ›´æ–°...")

    # è·å–å½“å‰ä¿å­˜çš„çŠ¶æ€ä½œä¸ºåŸºå‡†
    last_info = workflow_manager.get_last_workflow_info(run_id)

    for attempt in range(1, max_retries + 1):
        try:
            # è·å–æœ€æ–°çŠ¶æ€
            workflow_info = get_workflow_info(run_id)

            # å¿«é€Ÿé€€å‡ºï¼šå¦‚æœçŠ¶æ€æ˜¯ completedï¼Œç«‹å³è¿”å›
            if workflow_info.get("status") == "completed":
                print(f"[INFO] ç¬¬ {attempt} æ¬¡æŸ¥è¯¢: å·¥ä½œæµå·²å®Œæˆï¼Œç«‹å³è¿”å›")
                workflow_manager.save_last_workflow_info(run_id, workflow_info)
                return workflow_info, attempt

            # æ£€æŸ¥ä¿¡æ¯æ˜¯å¦æœ‰å˜åŒ–
            if last_info is None or not compare_workflow_info(last_info, workflow_info):
                # ä¿¡æ¯æœ‰å˜åŒ–æˆ–é¦–æ¬¡è·å–
                print(f"[INFO] ç¬¬ {attempt} æ¬¡æŸ¥è¯¢: å·¥ä½œæµä¿¡æ¯å·²æ›´æ–°")
                workflow_manager.save_last_workflow_info(run_id, workflow_info)
                return workflow_info, attempt

            # ä¿¡æ¯æœªå˜åŒ–ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥è®¡ç®—ç­‰å¾…æ—¶é—´
            # å‰5æ¬¡ä½¿ç”¨0.5ç§’ï¼Œä¹‹åé€æ¸å¢åŠ åˆ°æœ€å¤§2ç§’
            if attempt <= 5:
                current_interval = initial_interval
            else:
                current_interval = min(initial_interval * (1.5 ** (attempt - 5)), 2.0)

            print(f"[INFO] ç¬¬ {attempt} æ¬¡æŸ¥è¯¢: å·¥ä½œæµä¿¡æ¯æœªå˜åŒ–ï¼Œç­‰å¾… {current_interval:.1f} ç§’åé‡è¯•...")
            time.sleep(current_interval)

        except Exception as e:
            print(f"[ERROR] ç¬¬ {attempt} æ¬¡æŸ¥è¯¢å¤±è´¥: {str(e)}")
            if attempt < max_retries:
                # å‡ºé”™æ—¶ä¹Ÿä½¿ç”¨é€€é¿ç­–ç•¥
                current_interval = min(initial_interval * (1.2 ** attempt), 2.0)
                time.sleep(current_interval)
            else:
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
                return {
                    "run_id": run_id,
                    "status": "error",
                    "message": f"æŸ¥è¯¢å·¥ä½œæµä¿¡æ¯å¤±è´¥: {str(e)}",
                    "data": {}
                }, attempt

    # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿¡æ¯ä»æœªå˜åŒ–
    print(f"[WARNING] å·¥ä½œæµ {run_id} åœ¨ {max_retries} æ¬¡æŸ¥è¯¢åä¿¡æ¯ä»æœªå˜åŒ–")
    workflow_info = get_workflow_info(run_id)  # æœ€åä¸€æ¬¡è·å–
    workflow_manager.save_last_workflow_info(run_id, workflow_info)
    return workflow_info, max_retries

def should_notify_user(run_id: str, new_info: Dict) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥é€šçŸ¥ç”¨æˆ·
    è¿”å›: True è¡¨ç¤ºéœ€è¦é€šçŸ¥ï¼ŒFalse è¡¨ç¤ºè·³è¿‡ï¼ˆå› ä¸ºä¿¡æ¯ç›¸åŒï¼‰
    """
    last_info = workflow_manager.get_last_workflow_info(run_id)

    # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è·å–ä¿¡æ¯ï¼Œéœ€è¦é€šçŸ¥
    if last_info is None:
        workflow_manager.save_last_workflow_info(run_id, new_info)
        workflow_manager.update_interaction_time(run_id)
        return True

    # æ¯”è¾ƒæ–°æ—§ä¿¡æ¯
    if compare_workflow_info(last_info, new_info):
        # ä¿¡æ¯ç›¸åŒï¼Œä¸é€šçŸ¥ç”¨æˆ·
        print(f"[DEBUG] å·¥ä½œæµ {run_id} ä¿¡æ¯æœªå˜åŒ–ï¼Œè·³è¿‡é€šçŸ¥")
        return False
    else:
        # ä¿¡æ¯ä¸åŒï¼Œæ›´æ–°ç¼“å­˜å¹¶é€šçŸ¥ç”¨æˆ·
        workflow_manager.save_last_workflow_info(run_id, new_info)
        workflow_manager.update_interaction_time(run_id)
        print(f"[DEBUG] å·¥ä½œæµ {run_id} ä¿¡æ¯å·²å˜åŒ–ï¼Œé€šçŸ¥ç”¨æˆ·")
        return True

def check_interrupted_workflows(history: List) -> Tuple[List, List, List]:
    """
    æ£€æŸ¥ä¸­æ–­çš„å·¥ä½œæµçŠ¶æ€
    è¿™ä¸ªå‡½æ•°ä¼šè¢«ã€Œåˆ·æ–°çŠ¶æ€ã€æŒ‰é’®è°ƒç”¨
    è¿”å›: (updated_history, display_images, file_paths)
    """
    display_images = []
    file_paths = []
    updated_history = history.copy()

    # æŸ¥æ‰¾æ‰€æœ‰ä¸­æ–­çš„å·¥ä½œæµ
    interrupted_run_ids = [
        run_id for run_id, state in workflow_manager.active_workflows.items()
        if state.get("status") == "interrupted"
    ]

    if not interrupted_run_ids:
        # æ²¡æœ‰ä¸­æ–­çš„å·¥ä½œæµ
        return updated_history, display_images, file_paths

    print(f"\n[INFO] å®šæ—¶æ£€æŸ¥ {len(interrupted_run_ids)} ä¸ªä¸­æ–­å·¥ä½œæµçš„çŠ¶æ€")

    for run_id in interrupted_run_ids:
        try:
            # è·å–æœ€æ–°çŠ¶æ€
            workflow_info = get_workflow_info(run_id)

            # æ›´æ–°å·¥ä½œæµçŠ¶æ€
            workflow_manager.save_workflow_state(run_id, workflow_info)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é€šçŸ¥ç”¨æˆ·
            if not should_notify_user(run_id, workflow_info):
                # ä¿¡æ¯æœªå˜åŒ–ï¼Œè·³è¿‡
                continue

            # æ ¹æ®çŠ¶æ€ç”Ÿæˆå“åº”
            if workflow_info.get("status") == "interrupted":
                # ä»ç„¶ä¸­æ–­ï¼Œç”Ÿæˆå“åº”
                response = format_interrupted_response(workflow_info, run_id)

                # æ·»åŠ ç³»ç»Ÿæç¤ºï¼ˆä¸æ·»åŠ åˆ°å¯¹è¯å†å²ï¼Œé¿å…é‡å¤ï¼‰
                # è¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦è¦æ·»åŠ åˆ°å†å²ä¸­
                # workflow_manager.add_to_history(run_id, "assistant", response)
                # updated_history.append([None, response])

                print(f"[INFO] å·¥ä½œæµ {run_id} ä»å¤„äºä¸­æ–­çŠ¶æ€")

            elif workflow_info.get("status") == "completed":
                # å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆå“åº”
                response, imgs, files = format_completed_response(workflow_info, run_id)

                workflow_manager.add_to_history(run_id, "assistant", response)
                updated_history.append([None, response])
                display_images.extend(imgs)
                file_paths.extend(files)

                # æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆ
                workflow_manager.save_workflow_state(run_id, {
                    **workflow_info,
                    "status": "completed"
                })

                print(f"[INFO] å·¥ä½œæµ {run_id} å·²å®Œæˆ")

        except Exception as e:
            error_msg = f"âŒ æ£€æŸ¥å·¥ä½œæµ {run_id} æ—¶å‡ºé”™: {str(e)}"
            print(f"[ERROR] {error_msg}")

    return updated_history, display_images, file_paths


# ==================== ç»“æœå¤„ç†å‡½æ•° ====================

def process_tool_results(tool_output: Dict, run_id: str) -> Tuple[str, List, List]:
    """
    å¤„ç†å·¥å…·è¾“å‡ºç»“æœï¼Œæ ¼å¼åŒ–ä¸ºå‰ç«¯å±•ç¤º
    è¿”å›: (summary_text, display_images, file_paths)
    """
    if "result" not in tool_output:
        return tool_output.get("message", "å¤„ç†å®Œæˆ"), [], []

    result = tool_output["result"]
    files = result.get("files", [])
    images = result.get("images", [])

    display_images = []
    file_paths = []
    summary_parts = []

    # å¤„ç†æ¶ˆæ¯
    summary_parts.append(f"âœ… {tool_output.get('message', 'å¤„ç†å®Œæˆ')}")

    # å¤„ç†å›¾ç‰‡
    if images:
        summary_parts.append(f"\nğŸ“Š ç”Ÿæˆäº† {len(images)} ä¸ªå¯è§†åŒ–å›¾è¡¨ï¼š")
        for idx, img in enumerate(images, 1):
            if isinstance(img, Image.Image):
                display_images.append(img)
                summary_parts.append(f"  - å›¾è¡¨ {idx}: {img.size[0]}x{img.size[1]} åƒç´ ")
            else:
                summary_parts.append(f"  - å›¾è¡¨ {idx}: [éå›¾ç‰‡å¯¹è±¡]")

    # å¤„ç†æ–‡ä»¶
    if files:
        summary_parts.append(f"\nğŸ“ ç”Ÿæˆäº† {len(files)} ä¸ªæ•°æ®æ–‡ä»¶ï¼š")
        for file_path in files:
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                file_name = os.path.basename(file_path)
                file_paths.append(file_path)
                summary_parts.append(f"  - {file_name} ({file_size} bytes)")
            else:
                summary_parts.append(f"  - {os.path.basename(file_path)} [æ–‡ä»¶ä¸å­˜åœ¨]")

    # è·å–å†å²ä¿¡æ¯
    history = workflow_manager.get_history(run_id)
    if history:
        summary_parts.append(f"\nğŸ’¬ å¯¹è¯è½®æ¬¡: {len(history)}")

    summary = "\n".join(summary_parts)
    return summary, display_images, file_paths

def format_interrupted_response(workflow_info: Dict, run_id: str) -> str:
    """æ ¼å¼åŒ–ä¸­æ–­çŠ¶æ€å“åº”"""
    message = workflow_info.get("message", "å·¥ä½œæµéœ€è¦æ›´å¤šä¿¡æ¯æ‰èƒ½ç»§ç»­")

    response = f"â¸ï¸ **å·¥ä½œæµå·²æš‚åœ**\n\n{message}\n\n"
    response += "è¯·æä¾›éœ€è¦çš„ä¿¡æ¯ä»¥ç»§ç»­å·¥ä½œæµã€‚"

    return response

def format_timeout_response(workflow_info: Dict, run_id: str, attempts: int) -> str:
    """æ ¼å¼åŒ–è¶…æ—¶å“åº” - å½“è½®è¯¢å¤šæ¬¡åå·¥ä½œæµä¿¡æ¯ä»æœªå˜åŒ–æ—¶ä½¿ç”¨"""
    message = workflow_info.get("message", "å·¥ä½œæµæ­£åœ¨å¤„ç†ä¸­")
    status = workflow_info.get("status", "unknown")

    # ä¼°ç®—ç­‰å¾…æ—¶é—´ï¼ˆä½¿ç”¨æ™ºèƒ½é€€é¿ç­–ç•¥ï¼‰
    estimated_wait_time = sum(0.5 if i <= 5 else min(0.5 * (1.5 ** (i - 5)), 2.0) for i in range(1, attempts + 1))

    response = f"â³ **å·¥ä½œæµå“åº”è¶…æ—¶**\n\n"
    response += f"æŠ±æ­‰ï¼Œåœ¨å·¥ä½œæµå¤„ç†è¿‡ç¨‹ä¸­ç­‰å¾…äº† {attempts} æ¬¡æŸ¥è¯¢ï¼ˆçº¦ {estimated_wait_time:.1f} ç§’ï¼‰ï¼Œ\n"
    response += f"ä½†å·¥ä½œæµçŠ¶æ€æ²¡æœ‰æ›´æ–°ã€‚\n\n"
    response += f"**å½“å‰çŠ¶æ€**: {status}\n"
    response += f"**æœ€æ–°æ¶ˆæ¯**: {message}\n\n"
    response += "è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š\n"
    response += "1. å·¥ä½œæµæ­£åœ¨å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œéœ€è¦æ›´é•¿æ—¶é—´\n"
    response += "2. å·¥ä½œæµå¯èƒ½é‡åˆ°äº†é—®é¢˜\n\n"
    response += "æ‚¨å¯ä»¥ï¼š\n"
    response += "- ç‚¹å‡»ã€ŒğŸ”„ åˆ·æ–°çŠ¶æ€ã€æŒ‰é’®æ‰‹åŠ¨æ£€æŸ¥å·¥ä½œæµè¿›åº¦\n"
    response += "- ç¨åå†è¯•\n"
    response += "- æä¾›æ›´å¤šä¿¡æ¯ä»¥å¸®åŠ©å·¥ä½œæµç»§ç»­"

    return response

def format_error_response(error_msg: str, run_id: str) -> str:
    """æ ¼å¼åŒ–é”™è¯¯å“åº”"""
    response = f"âŒ **å·¥ä½œæµå‡ºé”™**\n\n"
    response += f"æŠ±æ­‰ï¼Œå·¥ä½œæµ {run_id} é‡åˆ°äº†é”™è¯¯ï¼š\n\n"
    response += f"```\n{error_msg}\n```\n\n"
    response += "è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚"

    return response

def format_completed_response(workflow_info: Dict, run_id: str) -> Tuple[str, List, List]:
    """æ ¼å¼åŒ–å®ŒæˆçŠ¶æ€å“åº”"""
    # è·å–è§£æçš„å‚æ•°
    data = workflow_info.get("data", {})
    extracted_params = data.get("parameters", {})

    response_parts = []
    response_parts.append("âœ… **å·¥ä½œæµæ‰§è¡Œå®Œæˆ**\n")

    # æ˜¾ç¤ºæå–çš„å‚æ•°
    if extracted_params:
        response_parts.append("\nğŸ“‹ **è§£æçš„å‚æ•°ï¼š**\n")
        for key, value in extracted_params.items():
            response_parts.append(f"  - {key}: {value}")

    # è°ƒç”¨ç›¸åº”çš„å·¥å…·å‡½æ•°
    all_display_images = []
    all_file_paths = []
    tool_results = []

    # å‡è®¾ workflow_info ä¸­åŒ…å«äº†éœ€è¦è°ƒç”¨çš„å·¥å…·ä¿¡æ¯
    tools_to_run = data.get("tools", [])

    if not tools_to_run:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šå·¥å…·ï¼Œä½¿ç”¨é»˜è®¤å·¥å…·æˆ–å‚æ•°æ¨æ–­
        # è¿™é‡Œæ¨¡æ‹Ÿæ ¹æ®å‚æ•°é€‰æ‹©å·¥å…·
        if "compare" in str(extracted_params).lower():
            tools_to_run = ["inline_compare"]
        elif "statistical" in str(extracted_params).lower():
            tools_to_run = ["statistical_analysis"]
        else:
            # é»˜è®¤è¿è¡Œ inline_compare
            tools_to_run = ["inline_compare"]

    for tool_name in tools_to_run:
        if tool_name in TOOL_FUNCTIONS:
            try:
                print(f"\n[INFO] è°ƒç”¨å·¥å…·: {tool_name}")
                tool_output = TOOL_FUNCTIONS[tool_name](extracted_params)
                tool_results.append(tool_output)

                # å¤„ç†æ¯ä¸ªå·¥å…·çš„ç»“æœ
                summary, display_images, file_paths = process_tool_results(tool_output, run_id)
                response_parts.append(f"\n{summary}")
                all_display_images.extend(display_images)
                all_file_paths.extend(file_paths)

            except Exception as e:
                error_msg = f"âŒ å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}"
                response_parts.append(f"\n{error_msg}")
                print(f"[ERROR] {error_msg}")

    final_response = "\n".join(response_parts)
    return final_response, all_display_images, all_file_paths

# ==================== å¯¹è¯å¤„ç†é€»è¾‘ ====================

def process_user_message(user_input: str, history: List) -> Tuple[List, List, List]:
    """
    å¤„ç†ç”¨æˆ·æ¶ˆæ¯çš„ä¸»è¦é€»è¾‘
    ä½¿ç”¨è½®è¯¢æœºåˆ¶ç¡®ä¿æ¯æ¬¡ç”¨æˆ·è¾“å…¥éƒ½èƒ½å¾—åˆ°å“åº”
    è¿”å›: (updated_history, display_images, file_paths)
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„å·¥ä½œæµ
    active_run_id = None

    # æŸ¥æ‰¾æœ€è¿‘çš„ä¸­æ–­å·¥ä½œæµ
    for run_id, state in workflow_manager.active_workflows.items():
        if state.get("status") == "interrupted":
            active_run_id = run_id
            break

    display_images = []
    file_paths = []

    if active_run_id:
        # æœ‰ä¸­æ–­çš„å·¥ä½œæµï¼Œéœ€è¦æ¢å¤
        print(f"\n[INFO] æ£€æµ‹åˆ°ä¸­æ–­çš„å·¥ä½œæµ: {active_run_id}")

        # æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²
        workflow_manager.add_to_history(active_run_id, "user", user_input)

        # æ¸…é™¤æ—§çš„ç¼“å­˜çŠ¶æ€ï¼Œç¡®ä¿èƒ½æ£€æµ‹åˆ°å·¥ä½œæµæ¢å¤åçš„å˜åŒ–
        workflow_manager.last_workflow_info.pop(active_run_id, None)
        print(f"[DEBUG] å·²æ¸…é™¤æ—§çš„ç¼“å­˜çŠ¶æ€ï¼Œå‡†å¤‡æ£€æµ‹æ–°çŠ¶æ€")

        # æ¢å¤å·¥ä½œæµ
        resume_workflow(user_input, active_run_id)

        # ä½¿ç”¨ä¼˜åŒ–çš„è½®è¯¢æœºåˆ¶è·å–æ›´æ–°åçš„å·¥ä½œæµä¿¡æ¯ï¼ˆæœ€å¤šç­‰å¾…çº¦7.5ç§’ï¼‰
        # å‚æ•°: run_id, max_retries=15, initial_interval=0.5
        workflow_info, attempts = poll_workflow_info(active_run_id, max_retries=15, initial_interval=0.5)

        # æ›´æ–°çŠ¶æ€
        workflow_manager.save_workflow_state(active_run_id, workflow_info)
        workflow_manager.update_interaction_time(active_run_id)

        # æ ¹æ®çŠ¶æ€å’Œå°è¯•æ¬¡æ•°ç”Ÿæˆå“åº”
        if workflow_info.get("status") == "error":
            # æŸ¥è¯¢å‡ºé”™
            response = format_error_response(workflow_info.get("message", "æœªçŸ¥é”™è¯¯"), active_run_id)
            workflow_manager.add_to_history(active_run_id, "assistant", response)
            history.append([user_input, response])

        elif workflow_info.get("status") == "interrupted":
            # ä»ç„¶ä¸­æ–­
            if attempts >= 15:
                # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä¿¡æ¯ä»æœªå˜åŒ–ï¼Œè¿”å›è¶…æ—¶å“åº”
                response = format_timeout_response(workflow_info, active_run_id, attempts)
                workflow_manager.add_to_history(active_run_id, "assistant", response)
                history.append([user_input, response])
            else:
                # åœ¨é‡è¯•æœŸé—´å¾—åˆ°äº†æ›´æ–°çš„ä¸­æ–­çŠ¶æ€
                response = format_interrupted_response(workflow_info, active_run_id)
                workflow_manager.add_to_history(active_run_id, "assistant", response)
                history.append([user_input, response])

        elif workflow_info.get("status") == "completed":
            # å®Œæˆ
            response, display_images, file_paths = format_completed_response(workflow_info, active_run_id)
            workflow_manager.add_to_history(active_run_id, "assistant", response)
            history.append([user_input, response])

            # æ›´æ–°çŠ¶æ€ä¸ºå·²å®Œæˆ
            workflow_manager.save_workflow_state(active_run_id, {
                **workflow_info,
                "status": "completed"
            })

        else:
            # æœªçŸ¥çŠ¶æ€
            response = f"âš ï¸ æœªçŸ¥çš„å·¥ä½œæµçŠ¶æ€: {workflow_info.get('status')}"
            workflow_manager.add_to_history(active_run_id, "assistant", response)
            history.append([user_input, response])

    else:
        # æ²¡æœ‰æ´»è·ƒå·¥ä½œæµï¼Œå¯åŠ¨æ–°çš„
        print(f"\n[INFO] å¯åŠ¨æ–°çš„å·¥ä½œæµ")

        # å¯åŠ¨å·¥ä½œæµ
        run_id = start_workflow(user_input)

        # åˆå§‹åŒ–å·¥ä½œæµçŠ¶æ€
        workflow_manager.add_to_history(run_id, "user", user_input)

        # ä½¿ç”¨ä¼˜åŒ–çš„è½®è¯¢æœºåˆ¶è·å–å·¥ä½œæµä¿¡æ¯ï¼ˆæœ€å¤šç­‰å¾…çº¦7.5ç§’ï¼‰
        workflow_info, attempts = poll_workflow_info(run_id, max_retries=15, initial_interval=0.5)

        # ä¿å­˜çŠ¶æ€
        workflow_manager.save_workflow_state(run_id, workflow_info)
        workflow_manager.update_interaction_time(run_id)

        # æ ¹æ®çŠ¶æ€ç”Ÿæˆå“åº”
        if workflow_info.get("status") == "error":
            # æŸ¥è¯¢å‡ºé”™
            response = format_error_response(workflow_info.get("message", "æœªçŸ¥é”™è¯¯"), run_id)
            workflow_manager.add_to_history(run_id, "assistant", response)
            history.append([user_input, response])

        elif workflow_info.get("status") == "interrupted":
            # ä¸­æ–­çŠ¶æ€
            if attempts >= 15:
                # å¯åŠ¨åç«‹å³è¶…æ—¶ï¼Œè¯´æ˜å·¥ä½œæµå¯èƒ½æœ‰é—®é¢˜
                response = format_timeout_response(workflow_info, run_id, attempts)
                workflow_manager.add_to_history(run_id, "assistant", response)
                history.append([user_input, response])
            else:
                # æ­£å¸¸çš„ä¸­æ–­çŠ¶æ€
                response = format_interrupted_response(workflow_info, run_id)
                workflow_manager.add_to_history(run_id, "assistant", response)
                history.append([user_input, response])

        elif workflow_info.get("status") == "completed":
            # å®Œæˆ
            response, display_images, file_paths = format_completed_response(workflow_info, run_id)
            workflow_manager.add_to_history(run_id, "assistant", response)
            history.append([user_input, response])

        else:
            # æœªçŸ¥çŠ¶æ€
            response = f"âš ï¸ æœªçŸ¥çš„å·¥ä½œæµçŠ¶æ€: {workflow_info.get('status')}"
            workflow_manager.add_to_history(run_id, "assistant", response)
            history.append([user_input, response])

    return history, display_images, file_paths

def create_gradio_interface():
    """åˆ›å»º Gradio ç•Œé¢"""

    custom_css = """
    /* å…¨å±€æ ·å¼ */
    .gradio-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;
        background: #f5f7fa !important;
        min-height: 100vh;
        color: #111827;
    }

    /* ä¸»å®¹å™¨ */
    .gradio-container > .main {
        background-color: #ffffff;
        border-radius: 16px;
        padding: 28px;
        margin: 20px;
        border: 1px solid #e5e7eb;
        box-shadow: 0 12px 30px rgba(17, 24, 39, 0.08);
    }

    /* æ ‡é¢˜æ ·å¼ */
    .gradio-container .markdown {
        color: #111827;
        font-size: 16px;
    }

    /* èŠå¤©ç•Œé¢ */
    .chatbot {
        background: #f9fafb;
        border-radius: 14px !important;
        border: 1px solid #e5e7eb;
    }

    /* ç”¨æˆ·æ¶ˆæ¯æ°”æ³¡ */
    .chatbot .user-message {
        background: #2563eb !important;
        color: #ffffff !important;
        border-radius: 16px 16px 4px 16px !important;
        box-shadow: 0 4px 12px rgba(37, 99, 235, 0.25);
        margin: 8px 0;
        padding: 12px 16px;
    }

    /* æœºå™¨äººæ¶ˆæ¯æ°”æ³¡ */
    .chatbot .bot-message {
        background: #ffffff !important;
        color: #111827 !important;
        border-radius: 16px 16px 16px 4px !important;
        box-shadow: 0 2px 8px rgba(17, 24, 39, 0.06);
        border: 1px solid #e5e7eb;
        margin: 8px 0;
        padding: 12px 16px;
    }

    /* è¾“å…¥æ¡†æ ·å¼ */
    .gradio-container input[type="text"], .gradio-container textarea {
        background-color: #ffffff;
        border: 1px solid #d1d5db;
        border-radius: 10px;
        padding: 12px 14px;
        font-size: 15px;
        transition: all 0.2s ease;
        box-shadow: none;
    }

    .gradio-container input[type="text"]:focus, .gradio-container textarea:focus {
        border-color: #2563eb;
        box-shadow: 0 0 0 3px rgba(37, 99, 235, 0.15);
        outline: none;
    }

    /* æŒ‰é’®æ ·å¼ */
    .gradio-container button {
        border-radius: 10px !important;
        font-weight: 600 !important;
        transition: all 0.2s ease !important;
        box-shadow: none !important;
        border: 1px solid #d1d5db !important;
        padding: 10px 18px !important;
        font-size: 14px !important;
        background: #ffffff !important;
        color: #111827 !important;
    }

    .gradio-container button:hover {
        background: #f9fafb !important;
    }

    .gradio-container button:active {
        transform: translateY(1px) !important;
    }

    /* ä¸»è¦æŒ‰é’® */
    .gradio-container button.primary {
        background: #2563eb !important;
        color: #ffffff !important;
        border-color: #2563eb !important;
    }

    .gradio-container button.primary:hover {
        background: #1d4ed8 !important;
        border-color: #1d4ed8 !important;
    }

    /* æ¬¡è¦æŒ‰é’® */
    .gradio-container button.secondary {
        background: #6b7280 !important;
        color: #ffffff !important;
        border-color: #6b7280 !important;
    }

    .gradio-container button.secondary:hover {
        background: #4b5563 !important;
        border-color: #4b5563 !important;
    }

    /* åœæ­¢æŒ‰é’® */
    .gradio-container button.stop {
        background: #374151 !important;
        color: #ffffff !important;
        border-color: #374151 !important;
    }

    .gradio-container button.stop:hover {
        background: #1f2937 !important;
        border-color: #1f2937 !important;
    }

    /* å›¾åº“æ ·å¼ */
    #results_gallery {
        background: #ffffff;
        border-radius: 14px;
        padding: 14px;
        border: 1px solid #e5e7eb;
    }

    /* æŠ˜å é¢æ¿æ ·å¼ */
    .gradio-container .accordion {
        border: 1px solid #e5e7eb;
        border-radius: 12px;
        background-color: #f9fafb;
    }

    .gradio-container .accordion button {
        background: #2563eb !important;
        color: #ffffff !important;
        font-weight: 600 !important;
        border: none !important;
    }

    /* ç¤ºä¾‹åŒºåŸŸæ ·å¼ */
    .gradio-container .examples {
        background: #f9fafb;
        border-radius: 14px;
        padding: 18px;
        border: 1px dashed #d1d5db;
    }

    /* æ ‡ç­¾æ ·å¼ */
    .gradio-container label {
        color: #4b5563;
        font-weight: 600;
        font-size: 14px;
        margin-bottom: 8px;
    }

    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ */
    .gradio-container .file-container {
        border: 1px dashed #d1d5db;
        border-radius: 10px;
        background: #ffffff;
        padding: 16px;
        transition: all 0.2s ease;
    }

    .gradio-container .file-container:hover {
        border-color: #2563eb;
        background: #f9fafb;
    }

    /* æ»šåŠ¨æ¡æ ·å¼ */
    ::-webkit-scrollbar {
        width: 10px;
        height: 10px;
    }

    ::-webkit-scrollbar-track {
        background: #f3f4f6;
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb {
        background: #cbd5e1;
        border-radius: 10px;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: #94a3b8;
    }

    /* åŠ¨ç”»æ•ˆæœ */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(6px); }
        to { opacity: 1; transform: translateY(0); }
    }

    .gradio-container > .main {
        animation: fadeIn 0.35s ease-out;
    }

    /* çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .status-indicator {
        display: inline-block;
        width: 10px;
        height: 10px;
        border-radius: 50%;
        margin-right: 8px;
        animation: pulse 2s infinite;
    }

    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }

    /* å“åº”å¼è®¾è®¡ */
    @media (max-width: 768px) {
        .gradio-container > .main {
            padding: 16px;
            margin: 10px;
        }
    }
    """

    with gr.Blocks(css=custom_css, title="ğŸ¤– æ™ºèƒ½å·¥ä½œæµåŠ©æ‰‹", theme=gr.themes.Soft()) as app:

        # é¡¶éƒ¨æ ‡é¢˜åŒº
        gr.HTML("""
        <div style="text-align: center; margin-bottom: 24px; padding: 18px; background: #f9fafb; border-radius: 14px; border: 1px solid #e5e7eb;">
            <h1 style="color: #111827; margin: 0; font-size: 30px; font-weight: 700;">ğŸ¤– æ™ºèƒ½å·¥ä½œæµåŠ©æ‰‹</h1>
            <p style="color: #6b7280; margin: 8px 0 0 0; font-size: 14px;">
                æ”¯æŒ AI æ™ºèƒ½ä½“çš„å¤šè½®å¯¹è¯ Â· è‡ªåŠ¨å¤„ç†ä¸­æ–­å’Œæ¢å¤çŠ¶æ€ Â· å®æ—¶ç»“æœå±•ç¤º
            </p>
        </div>
        """)

        # ç‰¹æ€§è¯´æ˜
        gr.HTML("""
        <div style="background: #ffffff; padding: 14px 18px; border-radius: 12px; margin-bottom: 18px; border: 1px solid #e5e7eb;">
            <div style="display: flex; align-items: center; gap: 10px; flex-wrap: wrap;">
                <span style="color: #2563eb; font-weight: 600;">âš¡ ä¼˜åŒ–ç‰¹æ€§ï¼š</span>
                <span style="color: #374151;">æ™ºèƒ½è½®è¯¢æœºåˆ¶</span>
                <span style="color: #d1d5db;">â€¢</span>
                <span style="color: #374151;">è‡ªåŠ¨è¶…æ—¶å¤„ç†</span>
                <span style="color: #d1d5db;">â€¢</span>
                <span style="color: #374151;">å®æ—¶çŠ¶æ€åˆ·æ–°</span>
                <span style="color: #d1d5db;">â€¢</span>
                <span style="color: #374151;">å¯è§†åŒ–ç»“æœå±•ç¤º</span>
            </div>
        </div>
        """)

        with gr.Row():
            # å·¦ä¾§ï¼šå¯¹è¯åŒºåŸŸ
            with gr.Column(scale=2):
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ å¯¹è¯å†å²",
                    height=500,
                    bubble_full_width=False,
                    avatar_images=(None, "ğŸ¤–"),
                    show_label=True
                )

                with gr.Row():
                    with gr.Column(scale=4):
                        msg_input = gr.Textbox(
                            label="",
                            placeholder="âœ¨ è¯·è¾“å…¥æ‚¨çš„éœ€æ±‚...ï¼ˆæ”¯æŒè‡ªç„¶è¯­è¨€æè¿°ï¼‰",
                            lines=2,
                            show_label=False,
                            container=False
                        )
                    with gr.Column(scale=1, min_width=120):
                        submit_btn = gr.Button("ğŸ“¤ å‘é€", variant="primary", size="lg")

                with gr.Row():
                    refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€", variant="secondary", scale=1)
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", variant="stop", scale=1)

            # å³ä¾§ï¼šç»“æœå±•ç¤ºåŒºåŸŸ
            with gr.Column(scale=1):
                gr.HTML("""
                <div style="text-align: center; margin: 12px 0; padding: 10px; background: #f9fafb; border-radius: 10px; border: 1px solid #e5e7eb;">
                    <h3 style="color: #111827; margin: 0; font-size: 16px; font-weight: 600;">ğŸ“Š åˆ†æç»“æœ</h3>
                </div>
                """)

                results_gallery = gr.Gallery(
                    label="ğŸ“ˆ ç”Ÿæˆçš„å›¾è¡¨",
                    show_label=True,
                    elem_id="results_gallery",
                    columns=1,
                    rows=5,
                    height="auto",
                    object_fit="contain"
                )

                gr.HTML("""
                <div style="text-align: center; margin: 16px 0 10px 0; padding: 10px; background: #f9fafb; border-radius: 10px; border: 1px solid #e5e7eb;">
                    <h3 style="color: #111827; margin: 0; font-size: 14px; font-weight: 600;">ğŸ“ ç”Ÿæˆæ–‡ä»¶</h3>
                </div>
                """)

                files_output = gr.File(
                    label="",
                    file_count="multiple",
                    interactive=False,
                    show_label=False
                )

        # çŠ¶æ€ä¿¡æ¯åŒºåŸŸ
        with gr.Accordion("ğŸ”§ ç³»ç»ŸçŠ¶æ€ä¿¡æ¯", open=False):
            with gr.Row():
                with gr.Column():
                    status_info = gr.Textbox(
                        label="ğŸ“Š å½“å‰çŠ¶æ€",
                        value="âœ… ç³»ç»Ÿå‡†å¤‡å°±ç»ª",
                        interactive=False
                    )
                with gr.Column():
                    active_workflows_info = gr.JSON(
                        label="ğŸ”„ æ´»è·ƒçš„å·¥ä½œæµ",
                        value={},
                        visible=True
                    )

        # ç¤ºä¾‹é—®é¢˜åŒºåŸŸ
        gr.HTML("""
        <div style="text-align: center; margin: 22px 0 12px 0; padding: 10px; background: #f9fafb; border-radius: 10px; border: 1px solid #e5e7eb;">
            <h3 style="color: #111827; margin: 0; font-size: 16px; font-weight: 600;">ğŸ’¡ å¿«é€Ÿå¼€å§‹ - ç‚¹å‡»ç¤ºä¾‹</h3>
        </div>
        """)

        examples = gr.Examples(
            examples=[
                ["å¸®æˆ‘å¯¹æ¯”åˆ†æä¸€ä¸‹æ•°æ®é›†Aå’Œæ•°æ®é›†Bçš„å·®å¼‚"],
                ["å¯¹é”€å”®æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æï¼Œç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š"],
                ["åˆ†æè¿‡å»ä¸€å¹´çš„æ•°æ®è¶‹åŠ¿ï¼Œå¹¶é¢„æµ‹æœªæ¥èµ°å‘"],
                ["è®¡ç®—å„ä¸ªå˜é‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œç»˜åˆ¶çƒ­åŠ›å›¾"]
            ],
            inputs=msg_input,
            label=None,
            examples_per_page=4
        )

        def handle_submit(user_input, history):
            """å¤„ç†æäº¤"""
            if not user_input.strip():
                return history, [], "è¯·è¾“å…¥æ¶ˆæ¯", {}

            updated_history, display_images, file_paths = process_user_message(user_input, history)

            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            active_count = sum(
                1 for s in workflow_manager.active_workflows.values()
                if s.get("status") == "interrupted"
            )

            status_msg = f"æ´»è·ƒå·¥ä½œæµæ•°: {active_count} | æ€»å¯¹è¯æ•°: {len(workflow_manager.conversation_history)}"

            # display_images å·²ç»æ˜¯ PIL Image å¯¹è±¡åˆ—è¡¨ï¼Œå¯ä»¥ç›´æ¥ç”¨äºç”»å»Š
            gallery_images = display_images

            # file_paths å·²ç»æ˜¯æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            output_files = file_paths

            print(f"\n[DEBUG] è¿”å› {len(gallery_images)} ä¸ªå›¾ç‰‡")
            print(f"[DEBUG] è¿”å› {len(output_files)} ä¸ªæ–‡ä»¶: {output_files}")

            return (
                updated_history,
                gallery_images,
                output_files,
                status_msg,
                workflow_manager.active_workflows
            )

        def handle_clear():
            """æ¸…ç©ºå¯¹è¯"""
            workflow_manager.active_workflows.clear()
            workflow_manager.conversation_history.clear()
            workflow_manager.last_workflow_info.clear()
            workflow_manager.last_interaction_time.clear()
            # è¿”å›5ä¸ªå€¼ä»¥åŒ¹é… outputs: [chatbot, results_gallery, files_output, status_info, active_workflows_info]
            return [], [], [], "å¯¹è¯å·²æ¸…ç©º", {}

        def handle_refresh(history, gallery_images, file_paths):
            """æ‰‹åŠ¨åˆ·æ–°å·¥ä½œæµçŠ¶æ€"""
            updated_history, new_images, new_files = check_interrupted_workflows(history)

            # åˆå¹¶å›¾ç‰‡å’Œæ–‡ä»¶
            all_images = list(gallery_images) + new_images if gallery_images else new_images
            all_files = list(file_paths) + new_files if file_paths else new_files

            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            active_count = sum(
                1 for s in workflow_manager.active_workflows.values()
                if s.get("status") == "interrupted"
            )

            status_msg = f"æ´»è·ƒå·¥ä½œæµæ•°: {active_count} | æ€»å¯¹è¯æ•°: {len(workflow_manager.conversation_history)}"

            return (
                updated_history,
                all_images,
                all_files,
                status_msg,
                workflow_manager.active_workflows
            )

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            handle_submit,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        ).then(
            lambda: "",
            outputs=[msg_input]
        )

        msg_input.submit(
            handle_submit,
            inputs=[msg_input, chatbot],
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        ).then(
            lambda: "",
            outputs=[msg_input]
        )

        clear_btn.click(
            handle_clear,
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        )

        # ç»‘å®šåˆ·æ–°æŒ‰é’®äº‹ä»¶
        refresh_btn.click(
            handle_refresh,
            inputs=[chatbot, results_gallery, files_output],
            outputs=[chatbot, results_gallery, files_output, status_info, active_workflows_info]
        )

    return app

# ==================== ä¸»ç¨‹åºå…¥å£ ====================

if __name__ == "__main__":
    print("=" * 60)
    print("å·¥ä½œæµå¯¹è¯æœºå™¨äºº - Gradioç•Œé¢")
    print("=" * 60)
    print("\n[INFO] æ­£åœ¨å¯åŠ¨æœåŠ¡å™¨...")
    print("[INFO] æ¨¡æ‹Ÿå‡½æ•°å·²åŠ è½½ï¼Œåç»­è¯·æ›¿æ¢ä¸ºå®é™…å®ç°\n")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("outputs", exist_ok=True)

    # åˆ›å»ºå¹¶å¯åŠ¨åº”ç”¨
    app = create_gradio_interface()

    # å¯åŠ¨æœåŠ¡å™¨
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )
